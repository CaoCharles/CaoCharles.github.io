<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Charles&#39;s Blog</title>
  
  <subtitle>test</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://caocharles.github.io/"/>
  <updated>2018-08-29T18:35:40.113Z</updated>
  <id>https://caocharles.github.io/</id>
  
  <author>
    <name>查爾斯</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>統研深度學習讀書會</title>
    <link href="https://caocharles.github.io/%E7%B5%B1%E7%A0%94%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E8%AE%80%E6%9B%B8%E6%9C%83/"/>
    <id>https://caocharles.github.io/統研深度學習讀書會/</id>
    <published>2018-08-29T01:43:20.000Z</published>
    <updated>2018-08-29T18:35:40.113Z</updated>
    
    <content type="html"><![CDATA[<h2 id="讀書會簡介"><a href="#讀書會簡介" class="headerlink" title="讀書會簡介"></a>讀書會簡介</h2><h2 id="開學討論"><a href="#開學討論" class="headerlink" title="開學討論"></a>開學討論</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;讀書會簡介&quot;&gt;&lt;a href=&quot;#讀書會簡介&quot; class=&quot;headerlink&quot; title=&quot;讀書會簡介&quot;&gt;&lt;/a&gt;讀書會簡介&lt;/h2&gt;&lt;h2 id=&quot;開學討論&quot;&gt;&lt;a href=&quot;#開學討論&quot; class=&quot;headerlink&quot; title=&quot;開學討論&quot;
      
    
    </summary>
    
      <category term="讀書會" scheme="https://caocharles.github.io/categories/study-group/"/>
    
    
      <category term="Deep Learning" scheme="https://caocharles.github.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>深度學習</title>
    <link href="https://caocharles.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/"/>
    <id>https://caocharles.github.io/深度學習/</id>
    <published>2018-08-28T16:12:21.000Z</published>
    <updated>2018-08-29T18:35:16.897Z</updated>
    
    <content type="html"><![CDATA[<h2 id="類神經網路-歷史"><a href="#類神經網路-歷史" class="headerlink" title="類神經網路 歷史"></a>類神經網路 歷史</h2><p>人工智慧最早出現於1950年代。人工智慧的目標是希望能讓電腦像人一班思考與學習。被視為人工智慧之父的圖靈(Alan Mathison Turing)，提出了有名的圖靈測試:人類與機器對話，如果人類無法根據這些對話過程判斷對方是人或機器，即通過測試，認為這台電腦具有人工智慧。</p><p>隨著AI的發展日益茁壯，1980年代(Jhon Searle)，提出了對人工智慧的分類方式:</p><ul><li><p>強人工智慧(Strong AI) : 機器與人具有完整的認知能力。</p></li><li><p>弱人工智慧(Weak AI) : 機器設計看起來具有智慧即可。</p></li></ul><p>而深度學習是人工智慧中，現今成長最快的領域，隨著電腦的普及以及其CPU、GPU運算能力增強，我們可以透過世界上各個資料庫收集大量資料，將資料整理成類神經網路的格式，藉由模擬人類神經網路的運作方式，加上數學的演算法進行更新參數，就可以讓電腦學習分辨日常生活的事物，常見的深度學習架構，如多層感知器MLP、深度神經網路DNN、卷積神經網路CNN、遞迴神經網路RNN。</p><p>而這些深度學習的架構應用在視覺辨識、語音辨識、自然語言處理、生物醫學等領域，皆有非常好的效果。</p><p><img src="https://i.imgur.com/5BFVrX2.png" alt=""></p><p>人工智慧現在已廣泛運用在我們的日常生活之中，像是手寫辨識、圖像辨識、語音辨識，幾乎都存在於人手一台的手機之中，還有更進一步的運用，如自動駕駛，透過硬體上的更新，我們可以裝設感測器感應車子周圍的環境狀況，加上圖像辨識，並整合成資訊讓電腦判斷是否停車或繼續行駛，透過演算法讓電腦知道該如何做決定，到最後將會實現在市區行駛之中，隨著科技越來越進步，深度學習所應用的領域就越來越廣。</p><h2 id="類神經網路-簡介"><a href="#類神經網路-簡介" class="headerlink" title="類神經網路 簡介"></a>類神經網路 簡介</h2><p>[維基百科]</p><p>類神經網路簡稱（英語：Artificial Neural Network，ANN），簡稱<strong>神經網路</strong>（Neural Network，NN）或<strong>類神經網路</strong>，在機器學習和認知科學領域，是一種模仿生物神經網路（動物的中樞神經系統，特別是大腦）的結構和功能的數學模型或計算模型，用於對函式進行估計或近似。神經網路由大量的人工神經元聯結進行計算。大多數情況下人工神經網路能在外界資訊的基礎上改變內部結構，是一種自適應系統，通俗的講就是具備學習功能。</p><p>現代神經網路是一種非線性統計性資料建模工具。典型的神經網路具有以下三個部分：</p><ul><li><p><strong>結構</strong>（<strong>Architecture</strong>）<br>結構指定了網路中的變數和它們的拓撲關係。<br>例如:神經網路中的變數可以是神經元連接的權重（weights）和神經元的激勵值（activities of the neurons）。</p></li><li><p><strong>激勵函式（Activity Rule）</strong><br>大部分神經網路模型具有一個短時間尺度的動力學規則，來定義神經元如何根據其他神經元的活動來改變自己的激勵值。一般激勵函式依賴於網路中的權重（即該網路的參數）。</p></li></ul><ul><li><strong>學習規則（Learning Rule）</strong><br>學習規則指定了網路中的權重如何隨著時間推進而調整。</li></ul><p><img src="https://i.imgur.com/Gmo3LfJ.png" alt=""></p><p>上圖為一個簡單的多層感知器，我們利用這個網路</p><h2 id="類神經網路-應用"><a href="#類神經網路-應用" class="headerlink" title="類神經網路 應用"></a>類神經網路 應用</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;類神經網路-歷史&quot;&gt;&lt;a href=&quot;#類神經網路-歷史&quot; class=&quot;headerlink&quot; title=&quot;類神經網路 歷史&quot;&gt;&lt;/a&gt;類神經網路 歷史&lt;/h2&gt;&lt;p&gt;人工智慧最早出現於1950年代。人工智慧的目標是希望能讓電腦像人一班思考與學習。被視為人工智
      
    
    </summary>
    
      <category term="深度學習" scheme="https://caocharles.github.io/categories/deep-learning/"/>
    
    
      <category term="Deep Learning" scheme="https://caocharles.github.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>EM演算法</title>
    <link href="https://caocharles.github.io/EM%E6%BC%94%E7%AE%97%E6%B3%95/"/>
    <id>https://caocharles.github.io/EM演算法/</id>
    <published>2018-08-28T09:31:35.000Z</published>
    <updated>2018-09-03T03:56:46.102Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/1121509ac1dc" target="_blank" rel="noopener">參考網址</a><br><a href="http://web.mit.edu/6.435/www/Dempster77.pdf" target="_blank" rel="noopener">Maximum Likelihood from Incomplete Data via the EM Algorithm</a></p><hr><p><strong>最大期望演算法</strong>（<strong>Expectation-maximization algorithm</strong>，又稱<strong>期望最大化算法</strong>）<br>在資料分析中常用於分群，在給定群數及機率模型下，去尋找觀測值變數間的所隱藏的訊息，可用此演算法來估計機率模型中的參數估計或遺失值填補。</p><hr><h2 id="名詞介紹"><a href="#名詞介紹" class="headerlink" title="名詞介紹"></a>名詞介紹</h2><ul><li><p>樣本: $x$</p></li><li><p>概似函數:  $L(\theta|x)=p(x|\theta)$</p></li><li><p>目的: 找到能讓 $L(\theta|x)$ 最大化的參數</p></li></ul><p>我的想法就是找到符合我們樣本資料的”最大”概似函數的機率模型參數，<br>以往都是假設好機率模型中的參數，並計算其MLE，<br>現在透過樣本及樣本所隱藏的隱變數，來推導適合這些樣本的模型參數。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ul><li>argument : $y$ (遺失值或是隱變數)</li><li>complete-data likelihood : $L(\theta|x,y)=p(x,y|\theta)$ 加入隱變數後完整的概似函數</li><li>What about $max_\theta L(x,y)$?</li><li>need to recursively update y and $\hat\theta$?</li></ul><h2 id="E步驟-更新y"><a href="#E步驟-更新y" class="headerlink" title="E步驟(更新y)"></a>E步驟(更新y)</h2><p>根據現在給定的模型參數及樣本觀測值，我們去計算其log完整概似函數的期望值如下:<br>$$Q(\theta|\theta^{(t)})\equiv E_y[log p(x,y|\theta)|x,\theta^{(t)}]$$</p><h2 id="M步驟-更新參數-theta"><a href="#M步驟-更新參數-theta" class="headerlink" title="M步驟(更新參數$\theta$)"></a>M步驟(更新參數$\theta$)</h2><p>最大化E步驟獲得的期望值<br>$$\theta^{(t+1)} = arg max_\theta  Q(\theta|\theta^{t})$$</p><p><strong>重複上述過程直到收斂</strong></p><h2 id="EM推導"><a href="#EM推導" class="headerlink" title="EM推導"></a>EM推導</h2><ul><li>$X:observed \space data$</li><li>$Y:latent\space variable$</li></ul><p>$Log\space likelihood \space function$</p><p>$$ l(\theta) $$</p><p>$$= lnP(X|\theta) $$</p><p>$$= ln\sum_yP(X,y|\theta) $$</p><p>$$= ln(\sum_yP(X,y|\theta))\frac{Q(y)}{Q(y)}$$</p><p>$$\ge\sum_yQ(y)ln\frac{P(X,y|\theta)}{Q(y)} $$</p><p>$$\because log \in concave\space by\space Jensen’s\space inequality $$</p><p>$$(解決ln\sum 不好計算的問題，Q:機率分配) $$</p><p>$$= E_Q(ln\frac{P(X,y|\theta)}{Q(y)})$$</p><p>在$Jensen’s \: inequality 中，當E(x)中，x=常數時，等號成立。$</p><p>$$\Rightarrow\frac{P(X,y|\theta)}{Q(y)}=c \in Constant，且\sum_yQ(y)=1$$</p><p>$$\Rightarrow\sum_yP(X,y|\theta)=c\sum_yQ(y)=c$$</p><p>$$\Rightarrow Q(y)=\frac{P(X,y|\theta)}{\sum_yP(X,y|\theta)}=P(y|x_i,\theta)$$，</p><p>$$Q:在樣本給定下之隱藏變數條件分布$$</p><p>$$\therefore E_Q(ln\frac{P(X,y|\theta)}{Q(y)})=E_y(ln\frac{P(X,y|\theta)}{P(y|x_i,\theta)}|X,\theta)$$</p><p>$$\theta^{(t+1)}=arg\max\limits_\theta l(\theta)\Longleftrightarrow arg\max\limits_\theta\sum_{y}P(y|x_i,\theta^{(t)})ln\frac{P(X,y|\theta)}{P(y|x_i,\theta^{(t)})}$$</p><p>$$\: \: \Longleftrightarrow arg\max\limits_\theta\sum_{y}P(y|x_i,\theta^{(t)})lnP(X,y|\theta)=E_y(lnP(X,y|\theta)|X,\theta^{(t)})=Q(\theta|\theta^{(t)})$$</p><p>$$\therefore E-step :Find \: Q(\theta|\theta^{(t)})$$</p><p>$\Longleftrightarrow$ Find the expectation of the complete-data loglikelihood with respect to the missing data y given the observed data x and the current parameter estimates $\theta^{(t)}$.</p><p>$$M-step=\theta^{(t+1)}=arg\max\limits_\theta Q(\theta|\theta^{(t)})$$</p><h2 id="EM收斂性"><a href="#EM收斂性" class="headerlink" title="EM收斂性"></a>EM收斂性</h2><hr><h2 id="範例1"><a href="#範例1" class="headerlink" title="範例1"></a>範例1</h2><p>197 animals are distributed multinomially into four categories with cell-probabilities$(\frac{1}{2}+ \frac{\theta}{4}, \frac{(1-\theta)}{4}, \frac{(1-\theta)}{4}, \frac{\theta}{4})$, where $\theta \in (0,1)$is unknown</p><p>Observed Data:<br>$$x=(x_1,x_2,x_3,x_4)=(125,18,20,34)$$</p><p>Likelihood:<br>$$L(\theta；x)=\frac{n!}{x_1!x_2!x_3!x_4!}(\frac{1}{2}+\frac{\theta}{4})^{x_1}(\frac{1}{4}-\frac{\theta}{4})^{x_2}(\frac{1}{4}-\frac{\theta}{4})^{x_3}(\frac{\theta}{4})^{x_4}$$</p><p>Find MLE by maximizing loglikelihood</p><p>Now use EM to find MLE</p><p>假設我們的隱藏變數在a裡面，令$y=x_{11}+x_{12}$</p><p>完整的變數擴展為$(x_{11},x_{12},x_{2},x_{3},x_{4})$有5個</p><p>初始其參數  $(\frac{1}{2}, \frac{\theta}{4}, \frac{1}{4}-\frac{\theta}{4}, \frac{\theta}{4})$</p><p>其概似函數如下</p><p>$$L(\theta；x)=\frac{n!}{x_{11}!x_{12}!x_2!x_3!x_4!}(\frac{1}{2})^{x_{11}}(\frac{\theta}{4})^{x_{12}}(\frac{1}{4}-\frac{\theta}{4})^{x_{2}+x_{3}}(\frac{\theta}{4})^{x_{4}}$$</p><ul><li>E 步驟</li></ul><p>給定機率模型參數$\theta^{(t)}$和$(x_1,x_2,x_3,x_4)$，$$x_{11}=\frac{2x_{1}}{2+\theta}\quad and \quad x_{12}=\frac{\theta x_{1}}{2+\theta}$$</p><ul><li>M 步驟</li></ul><p>給定$(x_{11},x_{12},x_{3},x_{4},x_{5})$</p><p>$$\hat \theta=\frac{x_{12}+x_{4}}{x_{12}+x_{2}+x_{3}+x_{4}}$$</p><p><strong>重複以上步驟到參數迭代至穩定</strong></p><h2 id="範例2"><a href="#範例2" class="headerlink" title="範例2"></a>範例2</h2><h2 id="範例3"><a href="#範例3" class="headerlink" title="範例3"></a>範例3</h2><p>假設現在有兩枚硬幣A、B</p><ul><li><p><step1>我們用一枚公正的硬幣來決定，投擲 A 或 B 硬幣</step1></p></li><li><p><step2>依據<step1>結果，投擲 A 或 B 硬幣 1次，記錄其結果</step1></step2></p></li><li><p><step3>反覆進行n次，最終可得到類似如下結果: 10111011….</step3></p><ul><li>1表示正面，0表示反面</li></ul></li></ul><p>如果我們今天只能觀察到最終結果<step3>，無法知道每一次投擲來自哪一枚硬幣，該如何估計出兩個硬幣出現正面機率?</step3></p><p><sol>:</sol></p><p>Observed Data : $X=(x_1,x_2,…,x_n), x_i:正面出現次數$<br>A、B 出現正面機率 : $\theta =(p,q)$</p><p>$1^{\circ}$  從MLE想法出發</p><p>概似函數 :<br>$$L(\theta|X)=P(X|\theta)=\prod_{i=1}^nP(x_i|\theta)$$</p><p>$$\hat p=\frac{使用A硬幣骰到正面次數}{使用A硬幣總投擲次數}$$</p><p>$$\hat q=\frac{使用B硬幣骰到正面次數}{使用B硬幣總投擲次數}$$</p><p>但因為我們並不知道 $x_i$來自哪個硬幣(機率模型)，所以無法進行計算。</p><p>$2^{\circ}$ 嘗試添加隱藏變數，使其變成complete data，運用EM演算法</p><ul><li><p>根據observed data，我們無從得知 $x_i$來自哪個硬幣(機率模型)，    </p></li><li><p>因此我們添加一個隱藏變數 $y_i$，其表示 $x_i$ 來自哪個硬幣，$Y=(y_1,y_2,…,y_n)$</p></li></ul><p>$y_i$ ~ Ber(0.5)，$x_i$|$y_i$=1 ~ Ber( p )，$x_i$|$y_i$=0 ~ Ber( q )</p><p>E-step :</p><p>$$\Rightarrow$ $Q(\theta|\theta^{(t)})=E_y[ln(p(x,y|\theta))|x,\theta ^{(t)}]=E_y[\sum_{i=1}^{n}ln(p(y_i|\theta)p(x_i|y_i,\theta))|x,\theta^{(t)}]$$</p><p>$$=\sum_{i=1}^{n}E_y[ln(p(y_i|\theta)p(x_i|y_i,\theta))|x,\theta^{(t)}]=\sum_{i=1}^{n}\sum_{y_i=0}^{1}[ln(p(y_i|\theta)p(x_i|y_i,\theta))p(y_i|x_i,\theta^{(t)} )]$$</p><p>$$=\sum_{i=1}^{n}\sum_{j=0}^{1}[ln(p(y_i=j|\theta)p(x_i|y_i,\theta))p(y_i=j|x_i,\theta^{(t)} )]$$</p><p>其中$p(y_i=j|x_i,\theta^{(t)} )$ : 在第t次迭代下，當前數據來自哪個硬幣的機率</p><p>Q-step : </p><1><p>$$\frac{\partial Q}{\partial p}=\frac{\partial (\sum_{i=1}^{n}ln(\frac{1}{2}p^{x_i}(1-p)^{1-x_i})p(y_i=1|x_i,\theta^{(t)} )}{\partial p}$$</p><p>$$=\frac{\partial (\sum_{i=1}^{n}ln(\frac{1}{2})+x_iln(p)+(1-x_i)ln(1-p)p(y_i=1|x_i,\theta^{(t)} )}{\partial p}$$</p><p>$$=\sum_{i=1}^{n}(\frac{xi}{p}-\frac{(1-x_i)}{1-  p})p(y_i=1|x_i,\theta^{(t)} )=0$$</p><p>$$\Rightarrow p^{(t+1)}=\frac{\sum_{i=1}^{n}x_ip(y_i=1|x_i,\theta^{(t)})}{\sum_{i=1}^{n}p(y_i=1|x_i,\theta^{(t)})}$$</p><2><p>$$\frac{\partial Q}{\partial q}=0$$</p><p>同理可得,$$q^{(t+1)}=\frac{\sum_{i=1}^{n}x_ip(y_i=2|x_i,\theta^{(t)})}{\sum_{i=1}^{n}p(y_i=2|x_i,\theta^{(t)})}$$</p><p>$3^{\circ}$ 綜觀以上結果，可以發現實際上我們只需要計算出$p(y_i=j|x_i,\theta^{(t)} )$，就可以拿來進行EM迭代。</p><p>$\Rightarrow$ 給定初始值$(p^{(0)},q^{(0)})$，計算出$p(y_i=j|x_i,\theta^{(0)} )$，代入更新參數$p^{(t+1)},q^{(t+1)}$，重複迭代，直到收斂或者達到自行給定tolerance內.</p><p>$4^{\circ}$ 若<step2>改成依據<step1>結果，連續投擲 A 或 B 硬幣 10次，記錄其結果</step1></step2></p><ul><li><step3>反覆進行n次，最終可得到類似如下結果:<ul><li>1表示正面，0表示反面</li></ul></step3></li></ul><p><img src="https://i.imgur.com/TIuGBly.png" alt=""></p><p>最終Q-step 的參數公式 :<br>$$p^{(t+1)}=\frac{\sum_{i=1}^{n}x_ip(y_i=1|x_i,\theta^{(t)})}{\sum_{i=1}^{n}10p(y_i=1|x_i,\theta^{(t)}}$$</p><p>$$q^{(t+1)}=\frac{\sum_{i=1}^{n}x_ip(y_i=2|x_i,\theta^{(t)})}{\sum_{i=1}^{n}10p(y_i=2|x_i,\theta^{(t)})}$$</p><h2 id="Python-實作"><a href="#Python-實作" class="headerlink" title="Python 實作"></a>Python 實作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5組硬幣投擲結果(n=5,k=10)，1代表正面，0代表反面</span></span><br><span class="line">observations = np.array([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                         [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                         [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                         [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line">da=pd.DataFrame(observations,</span><br><span class="line">                index=[<span class="string">"第一次"</span>,<span class="string">"第二次"</span>,<span class="string">"第三次"</span>,<span class="string">"第四次"</span>,<span class="string">"第五次"</span>])</span><br><span class="line">da.columns = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>];da</span><br><span class="line"></span><br><span class="line"><span class="comment">###</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">em_single</span><span class="params">(priors,observations)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    EM算法-單次疊代</span></span><br><span class="line"><span class="string">    ------------</span></span><br><span class="line"><span class="string">    priors:[theta_A,theta_B]</span></span><br><span class="line"><span class="string">    observation:[m X n matrix]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    ---------------</span></span><br><span class="line"><span class="string">    new_priors:[new_theta_A,new_theta_B]</span></span><br><span class="line"><span class="string">    :param priors:</span></span><br><span class="line"><span class="string">    :param observations:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    counts = &#123;<span class="string">'A'</span>: &#123;<span class="string">'H'</span>: <span class="number">0</span>, <span class="string">'T'</span>: <span class="number">0</span>&#125;, <span class="string">'B'</span>: &#123;<span class="string">'H'</span>: <span class="number">0</span>, <span class="string">'T'</span>: <span class="number">0</span>&#125;&#125;</span><br><span class="line">    theta_A = priors[<span class="number">0</span>]</span><br><span class="line">    theta_B = priors[<span class="number">1</span>]</span><br><span class="line">    <span class="comment">#E step</span></span><br><span class="line">    <span class="keyword">for</span> observation <span class="keyword">in</span> observations:</span><br><span class="line">        len_observation = len(observation)      <span class="comment">#計算投擲次數</span></span><br><span class="line">        num_heads = observation.sum()           <span class="comment">#正面次數</span></span><br><span class="line">        num_tails = len_observation-num_heads   <span class="comment">#反面次數</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#二項分配公式求解</span></span><br><span class="line">        contribution_A = scipy.stats.binom.pmf(num_heads,len_observation,theta_A)    <span class="comment">#Bin(x,n,p)</span></span><br><span class="line">        contribution_B = scipy.stats.binom.pmf(num_heads,len_observation,theta_B)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#計算在給定資料、當前參數下，資料來自哪個硬幣的機率</span></span><br><span class="line">        weight_A = contribution_A / (contribution_A + contribution_B)     <span class="comment"># p(y=1|x,theta)</span></span><br><span class="line">        weight_B = contribution_B / (contribution_A + contribution_B)     <span class="comment"># p(y=0|x,theta)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#更新在當前參數下A，B硬幣產生的正反面次數</span></span><br><span class="line">        counts[<span class="string">'A'</span>][<span class="string">'H'</span>] += weight_A * num_heads  <span class="comment"># num += 1  =&gt; num = num+1， sum p(y_i=1|x,theta)*x_i</span></span><br><span class="line">        counts[<span class="string">'A'</span>][<span class="string">'T'</span>] += weight_A * num_tails</span><br><span class="line">        counts[<span class="string">'B'</span>][<span class="string">'H'</span>] += weight_B * num_heads</span><br><span class="line">        counts[<span class="string">'B'</span>][<span class="string">'T'</span>] += weight_B * num_tails</span><br><span class="line"></span><br><span class="line">    <span class="comment"># M step</span></span><br><span class="line">    new_theta_A = counts[<span class="string">'A'</span>][<span class="string">'H'</span>] / (counts[<span class="string">'A'</span>][<span class="string">'H'</span>] + counts[<span class="string">'A'</span>][<span class="string">'T'</span>])  <span class="comment">#sum p(y_i=1|x,theta)*x_i / sum 10*p(y_i=1|x,theta)</span></span><br><span class="line">    new_theta_B = counts[<span class="string">'B'</span>][<span class="string">'H'</span>] / (counts[<span class="string">'B'</span>][<span class="string">'H'</span>] + counts[<span class="string">'B'</span>][<span class="string">'T'</span>])  <span class="comment">#sum p(y_i=0|x,theta)*x_i / sum 10*p(y_i=1|x,theta)</span></span><br><span class="line">    <span class="keyword">return</span> [new_theta_A,new_theta_B]</span><br><span class="line">    </span><br><span class="line"><span class="comment">###</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">em</span><span class="params">(observations,prior,tol = <span class="number">1e-6</span>,iterations=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    EM算法</span></span><br><span class="line"><span class="string">    ：param observations :觀測數據</span></span><br><span class="line"><span class="string">    ：param prior：模型初始值</span></span><br><span class="line"><span class="string">    ：param tol：迭代结束阈值</span></span><br><span class="line"><span class="string">    ：param iterations：最大迭代次數</span></span><br><span class="line"><span class="string">    ：return：局部最佳的模型參數</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    iteration = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> iteration &lt; iterations:</span><br><span class="line">        new_prior = em_single(prior,observations)</span><br><span class="line">        delta_change = np.abs(prior[<span class="number">0</span>]-new_prior[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> delta_change &lt; tol:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            prior = new_prior</span><br><span class="line">            iteration +=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> new_prior,iteration</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"(p,q,iteration)="</span>,em(observations,[<span class="number">0.7</span>,<span class="number">0.5</span>]))</span><br></pre></td></tr></table></figure><p>Ans : (p,q,iteration)= ([0.79678865844706648, 0.51958340803243785], 12)</p></2></1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/1121509ac1dc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;參考網址&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://web.mit.edu/6.435/www/Dempste
      
    
    </summary>
    
      <category term="機器學習" scheme="https://caocharles.github.io/categories/machine-learning/"/>
    
    
      <category term="EM" scheme="https://caocharles.github.io/tags/EM/"/>
    
      <category term="Algorithm" scheme="https://caocharles.github.io/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>我的測試文章</title>
    <link href="https://caocharles.github.io/%E6%88%91%E7%9A%84%E6%B8%AC%E8%A9%A6%E6%96%87%E7%AB%A0/"/>
    <id>https://caocharles.github.io/我的測試文章/</id>
    <published>2018-08-27T08:23:30.000Z</published>
    <updated>2018-08-28T09:40:52.900Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://caocharles.github.io/">連結測試</a></p><p>打打看文字。</p><p>12345</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x+2y =5</span><br></pre></td></tr></table></figure><p>$$\sigma$$ </p><p>$$\frac{1}{2}$$ </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://caocharles.github.io/&quot;&gt;連結測試&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;打打看文字。&lt;/p&gt;
&lt;p&gt;12345&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gut
      
    
    </summary>
    
      <category term="這是分類" scheme="https://caocharles.github.io/categories/%E9%80%99%E6%98%AF%E5%88%86%E9%A1%9E/"/>
    
      <category term="這是子分類" scheme="https://caocharles.github.io/categories/%E9%80%99%E6%98%AF%E5%88%86%E9%A1%9E/%E9%80%99%E6%98%AF%E5%AD%90%E5%88%86%E9%A1%9E/"/>
    
    
      <category term="這是標籤" scheme="https://caocharles.github.io/tags/%E9%80%99%E6%98%AF%E6%A8%99%E7%B1%A4/"/>
    
      <category term="這是標籤2" scheme="https://caocharles.github.io/tags/%E9%80%99%E6%98%AF%E6%A8%99%E7%B1%A42/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://caocharles.github.io/hello-world/"/>
    <id>https://caocharles.github.io/hello-world/</id>
    <published>2018-08-27T07:58:15.056Z</published>
    <updated>2018-08-27T07:58:15.057Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
