<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Charles&#39;s Blog</title>
  
  <subtitle>test</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://caocharles.github.io/"/>
  <updated>2018-11-10T15:52:41.247Z</updated>
  <id>https://caocharles.github.io/</id>
  
  <author>
    <name>æŸ¥çˆ¾æ–¯</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>å•†æ¥­ç°¡å ±è£½ä½œ</title>
    <link href="https://caocharles.github.io/%E5%95%86%E6%A5%AD%E7%B0%A1%E5%A0%B1%E8%A3%BD%E4%BD%9C/"/>
    <id>https://caocharles.github.io/å•†æ¥­ç°¡å ±è£½ä½œ/</id>
    <published>2018-11-10T15:42:01.000Z</published>
    <updated>2018-11-10T15:52:41.247Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç°¡å ±èª²inåœ‹æ³°-11-10"><a href="#ç°¡å ±èª²inåœ‹æ³°-11-10" class="headerlink" title="ç°¡å ±èª²inåœ‹æ³° (11/10)"></a>ç°¡å ±èª²inåœ‹æ³° (11/10)</h1><ul><li>æ™‚é–“ : 2018/11/10 13:30-15:30</li><li>åœ°é» : åœ‹æ³°æ¼”è¬›å»³</li><li>èŒ¶é» : è²“èŒ¶ç”º</li></ul><h2 id="Lecture-1-å•†æ¥­ç°¡å ±è£½ä½œ"><a href="#Lecture-1-å•†æ¥­ç°¡å ±è£½ä½œ" class="headerlink" title="Lecture 1 å•†æ¥­ç°¡å ±è£½ä½œ"></a>Lecture 1 å•†æ¥­ç°¡å ±è£½ä½œ</h2><h3 id="ç°¡å ±å…§å®¹"><a href="#ç°¡å ±å…§å®¹" class="headerlink" title="ç°¡å ±å…§å®¹"></a>ç°¡å ±å…§å®¹</h3><ul><li>è¬›å¸« : é»ƒç´¹å³°</li><li>èª²ç¨‹ : å•†æ¥­ç°¡å ±è£½ä½œ</li></ul><p><img src="https://i.imgur.com/cuFRjCr.png" alt=""></p><p>è½å¾—æ‡‚ã€åå¾—ä½çš„ç°¡å ±</p><p>åªæœ‰15åˆ†é˜è¦æ€éº¼åšç°¡å ±</p><p><img src="https://i.imgur.com/ajnhJ8z.png" alt=""></p><h3 id="14-mins-å ±å‘Š"><a href="#14-mins-å ±å‘Š" class="headerlink" title="14 mins å ±å‘Š"></a>14 mins å ±å‘Š</h3><p><strong>æµç¨‹å®‰æ’</strong></p><ul><li>Hello 30s<ul><li>ç°¡å–®ä»‹ç´¹è‡ªå·±éšŠä¼</li></ul></li><li>Problem 1m<ul><li>é—¡è¿°å•é¡Œ : å®šç¾©å•é¡Œè¶Šç°¡å–®è¶Šå¥½</li></ul></li><li>Solution 4m<ul><li>F,A,B</li><li>Feature åŠŸèƒ½</li><li>Advantage å„ªé»</li><li>Benifit æ•ˆç›Š</li></ul></li><li>Demo 4m30s<ul><li>Steps</li><li>before/after</li></ul></li><li>Feedback 1m<ul><li>Who backs you up?</li></ul></li><li>Review 3m<ul><li>Recap,sum up</li></ul></li></ul><h3 id="æ¥æ£’çš„å•é¡Œ"><a href="#æ¥æ£’çš„å•é¡Œ" class="headerlink" title="æ¥æ£’çš„å•é¡Œ"></a>æ¥æ£’çš„å•é¡Œ</h3><ul><li>ä¸Šå°çš„äººè¦æ€éº¼æ¹Šåœ¨ä¸€èµ·ï¼Œå¦‚ä½•æ¥æ£’</li><li>é¿å…é‡è¤‡æ€§çš„è©±èª</li><li>é‡è¤‡æ¼”ç·´æ¸›å°‘é‡è¤‡æ€§</li></ul><h2 id="10mins-QA"><a href="#10mins-QA" class="headerlink" title="10mins QA"></a>10mins QA</h2><ul><li><p>Take notes(æº–å‚™ç´™ç­†)</p></li><li><p>Appendix(é™„ä»¶)</p></li></ul><h2 id="è£½ä½œç°¡å ±"><a href="#è£½ä½œç°¡å ±" class="headerlink" title="è£½ä½œç°¡å ±"></a>è£½ä½œç°¡å ±</h2><h3 id="ç¬¬1æ­¥-ä¸è¦å¥—ç”¨æ¨¡æ¿"><a href="#ç¬¬1æ­¥-ä¸è¦å¥—ç”¨æ¨¡æ¿" class="headerlink" title="ç¬¬1æ­¥(ä¸è¦å¥—ç”¨æ¨¡æ¿)"></a>ç¬¬1æ­¥(ä¸è¦å¥—ç”¨æ¨¡æ¿)</h3><h4 id="Make-your-temps"><a href="#Make-your-temps" class="headerlink" title="Make your temps"></a>Make your temps</h4><p><img src="https://i.imgur.com/eNpYZCu.png" alt=""><br><img src="https://i.imgur.com/m7U30FR.png" alt=""><br><img src="https://i.imgur.com/yBZJIfD.png" alt=""></p><ul><li>æŸ¥çˆ¾æ–¯çš„æ¨¡æ¿</li></ul><h3 id="ç¬¬2æ­¥-å­—å‹"><a href="#ç¬¬2æ­¥-å­—å‹" class="headerlink" title="ç¬¬2æ­¥(å­—å‹)"></a>ç¬¬2æ­¥(å­—å‹)</h3><p><img src="https://i.imgur.com/N8pCLlz.png" alt=""></p><ul><li>é¸æ“‡æ²’æœ‰è¥¯ç·šçš„å­—å‹æ¯”è¼ƒå¥½çœ‹</li><li>Google NOTO Sans(æ€æºé«”)</li><li>å¾®è»Ÿæ­£é»‘</li><li><p>å¾®è»Ÿé›…é»‘</p></li><li><p>å­—çš„å¤§å°(28ä»¥ä¸Š)ã€ç²—ç´°ã€é–“è·</p></li><li>ç”¨å­—çš„å¤§å°ä¾†æ’è¡¨(åšå‡ºåœ–è¡¨æ•ˆæœ)</li></ul><h3 id="ç¬¬3æ­¥-è¨Šæ¯"><a href="#ç¬¬3æ­¥-è¨Šæ¯" class="headerlink" title="ç¬¬3æ­¥(è¨Šæ¯)"></a>ç¬¬3æ­¥(è¨Šæ¯)</h3><p><img src="https://i.imgur.com/xsmvApn.png" alt=""></p><ul><li>Message = Info - Noise </li><li>å¼·èª¿é‡é»(é¡è‰²ã€ç²—ç´°ã€)</li><li>æ¬¡é‡é»åšå¼±åŒ–(åšä¸€å€‹é€æ˜åº¦80%çš„ç°ç‰‡æŠŠè³‡è¨Šè¦†è“‹ä½)</li></ul><h3 id="ç¬¬4æ­¥-åœ–ç‰‡"><a href="#ç¬¬4æ­¥-åœ–ç‰‡" class="headerlink" title="ç¬¬4æ­¥(åœ–ç‰‡)"></a>ç¬¬4æ­¥(åœ–ç‰‡)</h3><p><img src="https://i.imgur.com/uwxyAgE.png" alt=""></p><ul><li>é¸æ“‡é©åˆçš„åœ–ç‰‡</li><li>é¸æ“‡pngå»èƒŒå¥½çš„åœ–ç‰‡</li><li>ç”¨åœ–å»æœåœ–</li><li>ä½¿ç”¨photoshopå»èƒŒå®Œå†è²¼ä¸Š</li><li>png å¾ˆæ£’ï¼Œæœ‰å»èƒŒ</li></ul><h4 id="ICON"><a href="#ICON" class="headerlink" title="ICON"></a>ICON</h4><p><img src="https://i.imgur.com/hVzdAvp.png" alt=""></p><ul><li>å¯ä»¥æ‰¾è·Ÿå¤§æ¨¹çš„ICON(æ„Ÿè¦ºè »ä¸éŒ¯çš„)</li><li>å¿«é€Ÿæ‰¾å–ç¾æˆçš„ICON</li><li>nounproject(å‘é‡æª”)<ul><li><a href="https://thenounproject.com/" target="_blank" rel="noopener">https://thenounproject.com/</a></li></ul></li><li>flaticon(æŸ¥çˆ¾æ–¯æ„›ç”¨çš„)<ul><li><a href="https://www.flaticon.com/" target="_blank" rel="noopener">https://www.flaticon.com/</a></li></ul></li><li>undraw(åœ–)<ul><li><a href="https://undraw.co/" target="_blank" rel="noopener">https://undraw.co/</a></li></ul></li><li>æ‰¾çš„ICONè¦æœ‰ä¸€è‡´æ€§</li><li>æ¼¸å±¤ICON(ä½¿ç”¨photoshop)</li><li>ICONä¸‹é¢æœ€å¥½åŠ ä¸€è¡Œè¨»è§£</li></ul><h3 id="ç¬¬5æ­¥-Toneè‰²èª¿"><a href="#ç¬¬5æ­¥-Toneè‰²èª¿" class="headerlink" title="ç¬¬5æ­¥(Toneè‰²èª¿)"></a>ç¬¬5æ­¥(Toneè‰²èª¿)</h3><p><img src="https://i.imgur.com/zRKIzLx.png" alt=""></p><ul><li>è¨­å‚™çš„æ–°èˆŠ<ul><li>èˆŠçš„è¨­å‚™(ç™½åº•é»‘å­—è¼ƒå¥½)</li><li>æ–°çš„è¨­å‚™(é»‘åº•ç™½å­—è¼ƒå¥½)</li><li>è¢å¹•å¾ˆå¤§(é»‘åº•ç™½å­—è¼ƒå¥½)</li></ul></li><li>é¡è‰²ä¸Šçš„å–ç”¨<ul><li>é…åˆå…¬å¸çš„ä¸»é¡Œé¡è‰²</li><li>é¸æ“‡ç¾çš„ã€è€çœ‹çš„é¡è‰²</li><li>ç¬¦åˆè‡ªå·±ä¸»é¡Œçš„é¡è‰²</li></ul></li></ul><ul><li>PowerpointåªåƒMP4(æ¯”è³½æ‡‰è©²ç”¨ä¸åˆ°)</li></ul><h3 id="ç¬¬6æ­¥-Diagramsæ•¸æ“šåŠè³‡æ–™"><a href="#ç¬¬6æ­¥-Diagramsæ•¸æ“šåŠè³‡æ–™" class="headerlink" title="ç¬¬6æ­¥(Diagramsæ•¸æ“šåŠè³‡æ–™)"></a>ç¬¬6æ­¥(Diagramsæ•¸æ“šåŠè³‡æ–™)</h3><p><img src="https://i.imgur.com/PTcjlGf.png" alt=""></p><ul><li>åœ–è¡¨æœ€å¥½éƒ½é‡æ–°è£½ä½œä¸€æ¬¡</li><li>ä½¿ç”¨åœ–çš„æ–¹å¼è¡¨é”(åœ“é¤…åœ–)</li><li>ä¸èƒ½äº‚ç”¨ï¼Œæœƒè¢«æ¸…ç¥¥ç½µ</li></ul><h3 id="ç¬¬7æ­¥-Animation"><a href="#ç¬¬7æ­¥-Animation" class="headerlink" title="ç¬¬7æ­¥(Animation)"></a>ç¬¬7æ­¥(Animation)</h3><p><img src="https://i.imgur.com/Rz69rDD.png" alt=""></p><ul><li>æˆ‘ä¹Ÿä¸æƒ³ç”¨(è¿ªå£«å°¼çš„çœ‹èµ·ä¾†é‚„ä¸éŒ¯è€¶)</li></ul><p><img src="https://i.imgur.com/XMg06ag.png" alt=""></p><ul><li>ç°¡å ±æ²’å…§å®¹å¯ä»¥ç”¨å‹•ç•«è·Ÿè¯éº—èƒŒæ™¯å…‹æœ(å°¤å…¶æ˜¯æ¸…ç¥¥çš„èª²)</li></ul><h3 id="ç¬¬8æ­¥-Details-æˆ‘æœ€æ„›çš„ç´°ç¯€"><a href="#ç¬¬8æ­¥-Details-æˆ‘æœ€æ„›çš„ç´°ç¯€" class="headerlink" title="ç¬¬8æ­¥(Details æˆ‘æœ€æ„›çš„ç´°ç¯€)"></a>ç¬¬8æ­¥(Details æˆ‘æœ€æ„›çš„ç´°ç¯€)</h3><p><img src="https://i.imgur.com/Mr5ZntK.png" alt=""></p><ul><li>Alignment(ä¸€è‡´æ€§)<ul><li>å­—é«”ã€å¤§å°ã€åœ–è¡¨ã€ICONã€ä¸­è‹±æ–‡</li></ul></li><li>Use gradient()<ul><li>ä¸è¦ä½¿ç”¨è¨­è¨ˆå»ºè­°</li><li>å¿ æ–¼è‡ªå·±çš„ç¾æ„Ÿ</li></ul></li><li>Use less 3D()<ul><li>3Déæ™‚</li><li>ä¸è¦åå°„(ä¸æµè¡Œ)</li><li><strong>Position</strong></li></ul></li></ul><p><strong>Before v.s. After</strong></p><p><strong>Leave some balnk</strong></p><p><strong>Donâ€™t roll slides</strong></p><p><strong>On Time!!!!!</strong></p><ul><li>è¦åšé€å­—ç¨¿ï¼Œæ¸›å°‘è´…è©çš„ä½¿ç”¨ï¼ŒåŠ å¼·èªªè©±æ–¹å¼(å¾ˆé›£ä½†æ˜¯æœ‰ç”¨)</li><li>å¯ä»¥ç”¨ä¸è¬›è©±ä¾†<strong>å¼·èª¿</strong></li><li>æƒ³è¦è¡¨é”è‡ªå·±åšå¾ˆå¤šäº‹<ul><li>æ”¾å¾ˆå¤šæ±è¥¿ï¼Œæˆ–æ˜¯å¯†é›†çš„è¡¨æ ¼</li><li>ä¸ç”¨è¬›å¤ªå¤š</li><li>å°±è·Ÿå¯«æ¸…ç¥¥çš„ä½œæ¥­ä¸€æ¨£</li></ul></li></ul><h3 id="å¥½çœ‹çš„æ’ç‰ˆ"><a href="#å¥½çœ‹çš„æ’ç‰ˆ" class="headerlink" title="å¥½çœ‹çš„æ’ç‰ˆ"></a>å¥½çœ‹çš„æ’ç‰ˆ</h3><p><img src="https://i.imgur.com/uxlfDQY.png" alt=""></p><p><img src="https://i.imgur.com/68vfYzV.jpg" alt=""></p><p><img src="https://i.imgur.com/arHXPL3.jpg" alt=""></p><p><img src="https://i.imgur.com/XT8QBUe.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ç°¡å ±èª²inåœ‹æ³°-11-10&quot;&gt;&lt;a href=&quot;#ç°¡å ±èª²inåœ‹æ³°-11-10&quot; class=&quot;headerlink&quot; title=&quot;ç°¡å ±èª²inåœ‹æ³° (11/10)&quot;&gt;&lt;/a&gt;ç°¡å ±èª²inåœ‹æ³° (11/10)&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;æ™‚é–“ : 2018/11/10 
      
    
    </summary>
    
      <category term="ç°¡å ±èª²ç¨‹åœ¨åœ‹æ³°" scheme="https://caocharles.github.io/categories/%E7%B0%A1%E5%A0%B1%E8%AA%B2%E7%A8%8B%E5%9C%A8%E5%9C%8B%E6%B3%B0/"/>
    
    
      <category term="PPT" scheme="https://caocharles.github.io/tags/PPT/"/>
    
  </entry>
  
  <entry>
    <title>å•†æ¥­ç°¡å ±å°é¢¨</title>
    <link href="https://caocharles.github.io/%E5%95%86%E6%A5%AD%E7%B0%A1%E5%A0%B1%E5%8F%B0%E9%A2%A8/"/>
    <id>https://caocharles.github.io/å•†æ¥­ç°¡å ±å°é¢¨/</id>
    <published>2018-11-10T15:42:00.000Z</published>
    <updated>2018-11-10T16:35:38.078Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç°¡å ±èª²inåœ‹æ³°-11-10"><a href="#ç°¡å ±èª²inåœ‹æ³°-11-10" class="headerlink" title="ç°¡å ±èª²inåœ‹æ³° (11/10)"></a>ç°¡å ±èª²inåœ‹æ³° (11/10)</h1><ul><li>æ™‚é–“ : 2018/11/10 15:30-17:00</li><li>åœ°é» : åœ‹æ³°æ¼”è¬›å»³</li><li>èŒ¶é» : è²“èŒ¶ç”º</li></ul><h2 id="Lecture-2-ç°¡å ±å•†æ¥­å°é¢¨"><a href="#Lecture-2-ç°¡å ±å•†æ¥­å°é¢¨" class="headerlink" title="Lecture 2 ç°¡å ±å•†æ¥­å°é¢¨"></a>Lecture 2 ç°¡å ±å•†æ¥­å°é¢¨</h2><h3 id="ç°¡å ±å…§å®¹"><a href="#ç°¡å ±å…§å®¹" class="headerlink" title="ç°¡å ±å…§å®¹"></a>ç°¡å ±å…§å®¹</h3><ul><li>è¬›å¸« : Ben ou</li><li>èª²ç¨‹ : ç°¡å ±å•†æ¥­å°é¢¨</li></ul><p><img src="https://i.imgur.com/sr0jgSW.png" alt=""></p><h3 id="æµç¨‹"><a href="#æµç¨‹" class="headerlink" title="æµç¨‹"></a>æµç¨‹</h3><p><img src="https://i.imgur.com/uKtEDtx.jpg" alt=""></p><h3 id="30ç§’é›»æ¢¯ç†è«–"><a href="#30ç§’é›»æ¢¯ç†è«–" class="headerlink" title="30ç§’é›»æ¢¯ç†è«–"></a>30ç§’é›»æ¢¯ç†è«–</h3><p><img src="https://i.imgur.com/EyANelg.png" alt=""></p><ul><li>èªå‡ºé©šäºº<ul><li>å¥½çš„é–‹å§‹æ˜¯æˆåŠŸçš„ä¸€åŠ</li><li>éƒé”å¤«æ–‡é›†(å¿«çŸ­å‘½)<ul><li>å¿«ï¼Œç—›å¿«</li><li>çŸ­ï¼Œç°¡æ˜æ‰¼è¦</li><li>å‘½ï¼Œä¸é›¢å‘½é¡Œ</li></ul></li></ul></li><li>çŸ­å°ç²¾æ‚<ul><li>æŠ“ä½æ ¹æœ¬ï¼Œç›´é”ä¸»é«”</li><li>æç¶±æŒˆé ˜ï¼ŒåŒ–ç¹ç‚ºç°¡</li></ul></li><li>æç…‰è§€é»<ul><li>è§€é»è¦ç¨ç‰¹éŸ¿äº®</li><li>æ­¸ç´è¦ç·Šæ¹Šï¼Œä¸è¶…éä¸‰æ¢</li></ul></li></ul><h3 id="éº¥è‚¯éŒ«é‡‘å­—å¡”æ–¹æ³•"><a href="#éº¥è‚¯éŒ«é‡‘å­—å¡”æ–¹æ³•" class="headerlink" title="éº¥è‚¯éŒ«é‡‘å­—å¡”æ–¹æ³•"></a>éº¥è‚¯éŒ«é‡‘å­—å¡”æ–¹æ³•</h3><ul><li><a href="https://www.managertoday.com.tw/articles/view/51650" target="_blank" rel="noopener">MECEåŸå‰‡-åƒè€ƒç¶²é </a></li><li><p>éº¥è‚¯éŒ«è§£æ±ºå•é¡Œ7æ­¥é©Ÿ</p></li><li><p>è§£æ±ºå•é¡Œçš„ä¸æ˜¯èˆ‡ç”Ÿä¿±ä¾†çš„å¤©è³¦ï¼Œè€Œæ˜¯å¯ä»¥é€éè‡ªæˆ‘è¨“ç·´åŸ¹é¤Šè€Œæˆï¼Œä½ ä¹Ÿèƒ½åƒéº¥è‚¯éŒ«äººä¸€æ¨£ï¼Œå€é€Ÿè§£æ±ºå•é¡Œã€‚</p></li></ul><p><img src="https://i.imgur.com/cC3uNcu.png" alt=""></p><ul><li>é‡‘å­—å¡”æ¶æ§‹</li></ul><p><img src="https://i.imgur.com/z7HTicZ.png" alt=""></p><ul><li>é‡‘å­—å¡”æ–¹æ³•</li></ul><p><img src="https://i.imgur.com/TtXXMQf.png" alt=""></p><ul><li>é‡‘å­—å¡”åŸç†å››å€‹åŸºæœ¬ç‰¹å¾µ</li></ul><p><img src="https://i.imgur.com/rBN0Ype.png" alt=""></p><ul><li>é‡‘å­—å¡”çµæ§‹</li></ul><p><img src="https://i.imgur.com/ojYcAmT.png" alt=""></p><h3 id="SDSçµæœæ³•"><a href="#SDSçµæœæ³•" class="headerlink" title="SDSçµæœæ³•"></a>SDSçµæœæ³•</h3><p><img src="https://i.imgur.com/AJ1BQG1.jpg" alt=""></p><ul><li>å…ˆè¬›çµè«–</li><li>å†è¬›ç¶“é</li><li>æœ€å¾Œå†é‡è¤‡çµè«–</li></ul><h3 id="æ³¨æ„äº‹é …"><a href="#æ³¨æ„äº‹é …" class="headerlink" title="æ³¨æ„äº‹é …"></a>æ³¨æ„äº‹é …</h3><p><img src="https://i.imgur.com/4PQ1goG.png" alt=""></p><h3 id="é–‹é ­"><a href="#é–‹é ­" class="headerlink" title="é–‹é ­"></a>é–‹é ­</h3><ul><li>ç ´é¡Œ</li><li>é‚è¼¯çµæ§‹</li><li>è¨˜æ†¶é»</li><li>ä½¿ç”¨è€…å ´æ™¯</li><li>äº’å‹•&amp;å¼µåŠ›</li></ul><h3 id="çµå°¾"><a href="#çµå°¾" class="headerlink" title="çµå°¾"></a>çµå°¾</h3><p><strong>Key Take Away</strong><br><img src="https://i.imgur.com/ILAcEXB.jpg" alt=""></p><ul><li>è‡³å°‘è®“è§€çœ¾è¨˜ä½ä¸€å€‹ç•«é¢</li></ul><p><strong>å³°å°¾æ•ˆæ‡‰</strong><br><img src="https://i.imgur.com/kbZbku4.jpg" alt=""></p><p><strong>è¨˜æ†¶é»</strong><br><img src="https://i.imgur.com/2VOINzm.jpg" alt=""></p><ul><li>æœ‰è¨˜æ†¶é»çš„çµæŸ!</li><li>Mamba out!</li></ul><div class="video-container"><iframe src="//www.youtube.com/embed/YK4E3nMR-KU" frameborder="0" allowfullscreen></iframe></div><ul><li>å†ä¸€å€‹è¨˜æ†¶é»çš„çµæŸ!</li><li>Kobe Bryant Slow Motion Shooting Compilation </li></ul><div class="video-container"><iframe src="//www.youtube.com/embed/9GkxFN8-PM0" frameborder="0" allowfullscreen></iframe></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ç°¡å ±èª²inåœ‹æ³°-11-10&quot;&gt;&lt;a href=&quot;#ç°¡å ±èª²inåœ‹æ³°-11-10&quot; class=&quot;headerlink&quot; title=&quot;ç°¡å ±èª²inåœ‹æ³° (11/10)&quot;&gt;&lt;/a&gt;ç°¡å ±èª²inåœ‹æ³° (11/10)&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;æ™‚é–“ : 2018/11/10 
      
    
    </summary>
    
      <category term="ç°¡å ±èª²ç¨‹åœ¨åœ‹æ³°" scheme="https://caocharles.github.io/categories/%E7%B0%A1%E5%A0%B1%E8%AA%B2%E7%A8%8B%E5%9C%A8%E5%9C%8B%E6%B3%B0/"/>
    
    
      <category term="PPT" scheme="https://caocharles.github.io/tags/PPT/"/>
    
  </entry>
  
  <entry>
    <title>äººå·¥æ™ºæ…§ç¬¬4å‘¨ç­†è¨˜</title>
    <link href="https://caocharles.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E7%AC%AC4%E5%91%A8%E7%AD%86%E8%A8%98/"/>
    <id>https://caocharles.github.io/äººå·¥æ™ºæ…§ç¬¬4å‘¨ç­†è¨˜/</id>
    <published>2018-10-08T09:30:19.000Z</published>
    <updated>2018-10-11T05:35:04.827Z</updated>
    
    <content type="html"><![CDATA[<h1 id="äººå·¥æ™ºæ…§èˆ‡æ‡‰ç”¨ç­†è¨˜4"><a href="#äººå·¥æ™ºæ…§èˆ‡æ‡‰ç”¨ç­†è¨˜4" class="headerlink" title="äººå·¥æ™ºæ…§èˆ‡æ‡‰ç”¨ç­†è¨˜4"></a>äººå·¥æ™ºæ…§èˆ‡æ‡‰ç”¨ç­†è¨˜4</h1><h2 id="ç¬¬å››å‘¨"><a href="#ç¬¬å››å‘¨" class="headerlink" title="ç¬¬å››å‘¨"></a>ç¬¬å››å‘¨</h2><p>å…¶ä»–çµ„å ±å‘Šè€å¸«çš„è¬›ç¾©<br>å¤§å®¶éƒ½åœ¨çœ‹è«å‡¡è¬›è§£é¡ç¥ç¶“ç¶²è·¯</p><h2 id="CSM-æ¼”ç®—æ³•"><a href="#CSM-æ¼”ç®—æ³•" class="headerlink" title="CSM æ¼”ç®—æ³•"></a>CSM æ¼”ç®—æ³•</h2><p>å¢åŠ nodeçš„æµç¨‹ (æœ‰7å€‹æ­¥é©Ÿ)</p><h4 id="The-proposed-CSM-learning-procedure"><a href="#The-proposed-CSM-learning-procedure" class="headerlink" title="The proposed CSM learning procedure"></a>The proposed CSM learning procedure</h4><ul><li><p>åˆ¤æ–·æ˜¯ä¸æ˜¯ç†Ÿæ‚‰çš„case</p></li><li><p>When we encounter a new case (a new input/output relationship), we first check if it is familiar to us.</p><ul><li>If it is, there is no spontaneous learning effort involved. Later the new case is merged into our knowledge system.</li><li><p>If it is not, we might cram this unfamiliar case first. The cramming results in a strict rule with respect to this unfamiliar case. Then we will soften the strictness of the new case  and do our best to merge the new case into our knowledge system.</p></li><li><p>é¢å°çš„å•é¡Œå¦‚æœæ˜¯æ›¾ç¶“æœ‰éçš„è³‡æ–™ï¼Œå‰‡æœƒé¸æ“‡ç›¸é—œçš„è³‡è¨Šå›æ‡‰ã€‚</p></li><li>é¢å°çš„å•é¡Œå¦‚æœæ˜¯æœªæ›¾æœ‰éçš„è³‡æ–™ï¼Œå‰‡æœƒé¸æ“‡å¢åŠ ä¸€å€‹æ–°å›æ‡‰ã€‚</li></ul></li></ul><h4 id="ASLFN-3å±¤çš„é¡ç¥ç¶“ç¶²è·¯-è¼¸å…¥-gt-éš±è—-gt-è¼¸å‡ºå±¤"><a href="#ASLFN-3å±¤çš„é¡ç¥ç¶“ç¶²è·¯-è¼¸å…¥-gt-éš±è—-gt-è¼¸å‡ºå±¤" class="headerlink" title="ASLFN (3å±¤çš„é¡ç¥ç¶“ç¶²è·¯ è¼¸å…¥-&gt;éš±è—-&gt;è¼¸å‡ºå±¤)"></a>ASLFN (3å±¤çš„é¡ç¥ç¶“ç¶²è·¯ è¼¸å…¥-&gt;éš±è—-&gt;è¼¸å‡ºå±¤)</h4><ul><li>The Adaptive Single-hidden Layer Feed-forward Neural Networks (ASLFN, i.e., the amount of adopted hidden nodes is variable)  (references: Tsaih 1993; Tsaih 1998; Tsaih and Cheng 2009; Huang, Yu, Tsaih and Huang Tsaih 2014; Kuo, Lin, and Hsu 2018)</li><li>2-class categorization problem and binary inputs {âˆ’1, 1}^ğ‘š </li></ul><p><img src="https://i.imgur.com/xrGDFGu.png" alt=""></p><h4 id="Activation-Function-æ¿€æ´»å‡½æ•¸"><a href="#Activation-Function-æ¿€æ´»å‡½æ•¸" class="headerlink" title="Activation Function (æ¿€æ´»å‡½æ•¸)"></a>Activation Function (æ¿€æ´»å‡½æ•¸)</h4><ul><li>tanh, the hyperbolic tangent activation function, is used in all hidden nodes.</li></ul><p><img src="https://i.imgur.com/WbOB70X.png" alt=""></p><h4 id="The-Activation-Value-of-Hidden-Nodes-éš±è—å±¤çš„æ¿€æ´»å€¼"><a href="#The-Activation-Value-of-Hidden-Nodes-éš±è—å±¤çš„æ¿€æ´»å€¼" class="headerlink" title="The Activation Value of Hidden Nodes (éš±è—å±¤çš„æ¿€æ´»å€¼)"></a>The Activation Value of Hidden Nodes (éš±è—å±¤çš„æ¿€æ´»å€¼)</h4><ul><li>æ¿€æ´»å‡½æ•¸ä¸èƒ½äº‚çµ¦ï¼Œæœƒæœ‰æ¢¯åº¦çˆ†ç‚¸çš„æƒ…å½¢ç™¼ç”Ÿã€‚</li></ul><p><img src="https://i.imgur.com/9SY8FZS.png" alt=""></p><p>$ğ±^ğ‘â‰¡(ğ‘¥_1^ğ‘,ğ‘¥_2^ğ‘, â€¦,ğ‘¥_ğ‘š^ğ‘ )Tï¼šğ‘¡â„ğ‘’ã€€inputã€€vectorã€€ofã€€theã€€ğ‘^thã€€case$</p><p>$ğ‘¤_{ğ‘–0}^{ğ»}ï¼štheã€€thresholdã€€valueã€€ofã€€theã€€ğ‘–^thã€€hiddenã€€node$</p><p>$ğ‘¤_ğ‘–ğ‘—^ğ»ï¼štheã€€weightã€€betweenã€€theã€€ğ‘–^thã€€hiddenã€€nodeã€€andã€€theã€€ğ‘—^thã€€inputã€€node$</p><p>$ğ°_ğ‘–^ğ»â‰¡(ğ‘¤_ğ‘–0^ğ»,ğ‘¤_ğ‘–1^ğ»,ğ‘¤_ğ‘–2^ğ», â€¦,ğ‘¤_ğ‘–ğ‘š^ğ» )^T$; $ğ°^ğ»â‰¡{({ğ°_1^ğ»}^T,{ğ°_2^ğ»}^T,â€¦,{ğ°_ğ‘^ğ»}^T)}^T$</p><h4 id="The-Activation-Value-of-the-Output-Node-è¼¸å‡ºå±¤çš„æ¿€æ´»æ•¸å€¼"><a href="#The-Activation-Value-of-the-Output-Node-è¼¸å‡ºå±¤çš„æ¿€æ´»æ•¸å€¼" class="headerlink" title="The Activation Value of the Output Node (è¼¸å‡ºå±¤çš„æ¿€æ´»æ•¸å€¼)"></a>The Activation Value of the Output Node (è¼¸å‡ºå±¤çš„æ¿€æ´»æ•¸å€¼)</h4><p><img src="https://i.imgur.com/UfkCp1N.png" alt=""></p><h4 id="Parameters-and-Indexes-åƒæ•¸"><a href="#Parameters-and-Indexes-åƒæ•¸" class="headerlink" title="Parameters and Indexes (åƒæ•¸)"></a>Parameters and Indexes (åƒæ•¸)</h4><ul><li>N denotes the number of all reference observations</li><li>m denotes the number of input nodes</li><li>p denotes the number of adopted hidden nodes; p equals 1 at the beginning and is adaptive</li><li>$ğ‘¦^ğ‘$ denotes the desired output of the $ğ‘^th$ case, with 1.0 and -1.0 being the desired outputs of classes 1 and 2</li><li>n denotes the $ğ‘›^th$ stage of handling n reference observations ${(ğ±^1, ğ‘¦^1), (ğ±^2, ğ‘¦^2), â€¦, (ğ±^ğ‘›, ğ‘¦^ğ‘›)}$, and $ğˆ(ğ‘›)$ is the set of indices of these observations. </li><li>At the $ğ‘›^th$ stage, the loss function $ğ¸_ğ‘› (ğ°)â‰¡\frac{âˆ‘_{ğ‘=1}^{ğ‘›}(ğ‘“(ğ±^ğ‘,ğ°)âˆ’ğ‘¦^ğ‘ )^2}{ğ‘›}+10^{-3}â€–ğ°â€–^2$</li><li>$ğˆ(ğ‘›)â‰¡ğˆ_1 (ğ‘›)âˆªğˆ_2 (ğ‘›)$, where$ğˆ_1(ğ‘›)$ and $ğˆ_2(ğ‘›)$ are the set of indices of n given cases in classes 1 and 2</li><li>At the $ğ‘›^th$ stage with the reference observations ${(ğ±^ğ‘, ğ‘¦^ğ‘): ğ‘âˆˆğˆ(ğ‘›)}$, we look for an acceptable SLFN, in which the condition L regarding ${ğ‘“(ğ±^ğ‘,ğ°), âˆ€ ğ‘âˆˆğˆ(ğ‘›)}$ is satisfied.</li></ul><h4 id="The-condition-ğ¿-regarding-ğ‘“-ğ±-ğ‘-ğ°-âˆ€-ğ‘âˆˆğˆ-ğ‘›"><a href="#The-condition-ğ¿-regarding-ğ‘“-ğ±-ğ‘-ğ°-âˆ€-ğ‘âˆˆğˆ-ğ‘›" class="headerlink" title="The condition ğ¿ regarding ${ğ‘“(ğ±^ğ‘,ğ°),  âˆ€ ğ‘âˆˆğˆ(ğ‘›)}$"></a>The condition ğ¿ regarding ${ğ‘“(ğ±^ğ‘,ğ°),  âˆ€ ğ‘âˆˆğˆ(ğ‘›)}$</h4><p><img src="https://i.imgur.com/oi1esy8.png" alt=""></p><h4 id="The-Learning-Goal-å­¸ç¿’ç›®æ¨™"><a href="#The-Learning-Goal-å­¸ç¿’ç›®æ¨™" class="headerlink" title="The Learning Goal (å­¸ç¿’ç›®æ¨™)"></a>The Learning Goal (å­¸ç¿’ç›®æ¨™)</h4><ul><li>At the $ğ‘›^{th}$ stage, through minimizing the loss function </li><li>$ğ¸_ğ‘› (ğ°)â‰¡\frac{âˆ‘_{ğ‘=1}^{ğ‘›}(ğ‘“(ğ±^ğ‘,ğ°)âˆ’ğ‘¦^ğ‘ )^2}{ğ‘›}+10^{-3} (âˆ‘_{ğ‘–=0}^{ğ‘}{(w_ğ‘–^o)^2} + âˆ‘_{ğ‘–=1}^{ğ‘}âˆ‘_{ğ‘—=0}^{ğ‘š}(ğ‘¤_{ğ‘–ğ‘—}^{ğ»})^2)$,the learning goal is to seek $ğ°$ where $ğ‘“(ğ±^ğ‘,ğ°)&gt;ğœˆ,âˆ€ ğ‘âˆˆğˆ_1 (ğ‘›)$  and $ğ‘“(ğ±^ğ‘,ğ°)â‰¤âˆ’ğœˆ,âˆ€ ğ‘âˆˆğˆ_2(ğ‘›)$, with $1&gt;ğœˆ&gt;0$. An alternative goal of learning is to seek ğ° that satisfies the condition ğ¿ regarding ${ğ‘“(ğ±^ğ‘,ğ°),  âˆ€ ğ‘âˆˆğˆ(ğ‘›)}$ </li><li>When $ğ›¼&gt;ğ›½$ is satisfied, $ğ‘“(ğ±^ğ‘,ğ°)â‰¥ğ‘£ ,âˆ€ ğ‘âˆˆğˆ_1(ğ‘›)$and $ğ‘“(ğ±^ğ‘,ğ°)â‰¤âˆ’ğ‘£,âˆ€ ğ‘âˆˆğˆ_2(ğ‘›)$ can be achieved by directly adjusting $ğ°^ğ‘œ$ according to the following:</li><li><img src="https://i.imgur.com/Ab3gKdl.png" alt=""></li></ul><h4 id="The-Proposed-CSM-Learning-Algorithm"><a href="#The-Proposed-CSM-Learning-Algorithm" class="headerlink" title="The Proposed CSM Learning Algorithm"></a>The Proposed CSM Learning Algorithm</h4><ul><li><p>Step 1: Initialize a SLFN with one hidden node with a randomized w. Obtain the first reference observation $(ğ±^1, ğ‘¦^1)$. Set $n = 2$.</p></li><li><p>Step 2: If $n &gt; N$, STOP.</p></li><li><p>Step 3: Present the n reference observations ${(ğ±^ğ‘, ğ‘¦^ğ‘): c âˆˆ I(n)}$.</p></li><li><p>Step 4: If the condition L regarding ${ğ‘“(ğ±^ğ‘,ğ°),  âˆ€ ğ‘âˆˆğˆ(ğ‘›)}$ is satisfied, go to Step 7.1.</p></li><li><p>Step 5: Save $w$.</p></li><li><p>Step 6: Apply the weight-tuning mechanism to $min_{ğ°}{â¡ğ¸(ğ°)}$ to adjust $w$ until one of the following two cases occurs:</p><ul><li>a. If the condition L regarding {ğ‘“(ğ±^ğ‘,ğ°),  âˆ€ ğ‘âˆˆğˆ(ğ‘›)} is satisfied, go to step 7.1.</li><li>b. If an unacceptable result is obtained, then<ul><li>Restore w</li><li>Let $p + 1 â†’ p$ and add to the existing SLFN the new $ğ‘^{th}$ hidden node with the following $ğ°_ğ‘^ğ»$ and $ğ°_ğ‘^ğ‘œ$:</li></ul></li></ul></li></ul><p><img src="https://i.imgur.com/LXvc9b4.png" alt=""></p><p><img src="https://i.imgur.com/E8JbXdq.png" alt=""></p><ul><li>Step 7.1: Apply the weight-tuning mechanism one hundred times to minimizing $ğ¸_ğ‘›(ğ°)$ to adjust $ğ°$, while keeping the condition L regarding ${ğ‘“(ğ±^ğ‘,ğ°),  âˆ€ ğ‘âˆˆğˆ(ğ‘›)}$ satisfied. </li><li>Step 7.2: Calculate $ğ‘”_ğ‘˜^â€²  âˆ€ ğ‘˜$, where $ğ°_ğ‘˜^{â€²}â‰¡ ğ° â€“ ({ğ‘¤_ğ‘˜^ğ‘œ, ğ°_ğ‘˜^ğ»})$, $ğ‘“(ğ±^ğ‘,ğ°_ğ‘˜^â€² )â‰¡ğ‘“(ğ±^ğ‘,ğ°)- ğ‘¤_{ğ‘˜}^{ğ‘œ}ğ‘_{ğ‘˜}^{ğ‘}$,$ğ›¼_ğ‘˜^â€²â‰¡ min_{ğ‘Ïµğˆ_1(ğ‘›)}â¡ğ‘“(ğ±^ğ‘,ğ°_ğ‘˜^â€² )$, $ğ›½_ğ‘˜^â€²â‰¡max_{ğ‘Ïµğˆ_2(ğ‘›)}â¡ğ‘“(ğ±^ğ‘,ğ°_ğ‘˜^â€²)$,  and $ğ‘”_ğ‘˜^â€²â‰¡ ğ›¼_ğ‘˜^â€²âˆ’ğ›½_ğ‘˜^â€²$.</li><li>Step 7.3: If $- \theta &gt;max_{1&lt;k&lt;p}{g_{k}^{â€˜}}$, where $\theta$ is a given constant, go to Step 2. </li><li>Step 7.4: If $max_{1&lt;k&lt;p}^â¡{ğ‘”_ğ‘˜^â€²} &gt; 0$, prune the $ğ‘–^{th}$ hidden node, in which ğ‘– is the first index of $argã€€max_{1&lt;k&lt;p}ğ‘”_{ğ‘˜}^{â€²}$, $p-1-&gt;p$, $ğ°_ğ‘–^â€²-&gt;w$, and go to Step 7.1.<br><img src="https://i.imgur.com/PC3Kvtw.png" alt=""><br><img src="https://i.imgur.com/SmjWEFq.png" alt=""></li></ul><h4 id="Flowchart-of-the-proposed-algorithm-æµç¨‹åœ–"><a href="#Flowchart-of-the-proposed-algorithm-æµç¨‹åœ–" class="headerlink" title="Flowchart of the proposed algorithm (æµç¨‹åœ–)"></a>Flowchart of the proposed algorithm (æµç¨‹åœ–)</h4><p><img src="https://i.imgur.com/beUgMB8.png" alt=""></p><h4 id="Explanation-of-the-Proposed-CSM-Learning-Algorithm-è§£é‡‹CSMå­¸ç¿’æ¼”ç®—æ³•"><a href="#Explanation-of-the-Proposed-CSM-Learning-Algorithm-è§£é‡‹CSMå­¸ç¿’æ¼”ç®—æ³•" class="headerlink" title="Explanation of the Proposed CSM Learning Algorithm (è§£é‡‹CSMå­¸ç¿’æ¼”ç®—æ³•)"></a>Explanation of the Proposed CSM Learning Algorithm (è§£é‡‹CSMå­¸ç¿’æ¼”ç®—æ³•)</h4><ul><li>Step 6 conducts the cramming mechanism.</li><li>The Appendix shows the properness of the cramming mechanism.</li><li>All hidden nodes use the same activation function, but some of them have the heterogeneity due to their large associated weights.</li><li>The total amount of used hidden nodes will be large if new hidden nodes are added frequently.</li><li>Step 7.1 and Step 7.5.c are designed to soften the heterogeneity.</li><li>At Step 6, Step 7.1 and Step 7.5.c, the weight-tuning mechanism is applied to minimizing $ğ¸_ğ‘›(ğ°)$ to adjust weights, while there is the regularization term in $ğ¸_ğ‘›(ğ°)$.</li><li>The total amount of used hidden nodes will be large if new hidden nodes are added frequently.</li><li>Step 7.2 to Step 7.5 are designed to merge the unfamiliar case into the knowledge system via reducing the total amount of used hidden nodes.</li><li>The pruning issue file shows the logic of the merging mechanism.</li></ul><h4 id="The-irrelevant-hidden-node"><a href="#The-irrelevant-hidden-node" class="headerlink" title="The irrelevant hidden node"></a>The irrelevant hidden node</h4><p><img src="https://i.imgur.com/YZjNMXi.png" alt=""></p><h4 id="The-irrelevance-examination-mechanism"><a href="#The-irrelevance-examination-mechanism" class="headerlink" title="The irrelevance examination mechanism"></a>The irrelevance examination mechanism</h4><p><img src="https://i.imgur.com/LtBrY6n.png" alt=""></p><h4 id="No-under-fitting"><a href="#No-under-fitting" class="headerlink" title="No under-fitting"></a>No under-fitting</h4><p><img src="https://i.imgur.com/he4OjoM.png" alt=""></p><h4 id="The-Regularization-term-in-ğ¸-ğ‘›-ğ°"><a href="#The-Regularization-term-in-ğ¸-ğ‘›-ğ°" class="headerlink" title="The Regularization term in $ğ¸_ğ‘›(ğ°)$"></a>The Regularization term in $ğ¸_ğ‘›(ğ°)$</h4><ul><li>Regarding the overfitting issue, the regularization term in the loss function $ğ¸_ğ‘›(ğ°)$ may prevent the model from doing too well on training data.</li></ul><h4 id="ç­†è¨˜"><a href="#ç­†è¨˜" class="headerlink" title="ç­†è¨˜"></a>ç­†è¨˜</h4><ul><li>æ¼”ç®—æ³•çš„åœæ­¢æº–å‰‡èˆ‡å­¸ç¿’ç›®æ¨™ä¸ä¸€å®šæœƒæœ‰é—œä¿‚</li></ul><h4 id="Cramming-ç¡¬èƒŒä¸‹å»"><a href="#Cramming-ç¡¬èƒŒä¸‹å»" class="headerlink" title="Cramming (ç¡¬èƒŒä¸‹å»)"></a>Cramming (ç¡¬èƒŒä¸‹å»)</h4><h4 id="Softening-è»ŸåŒ–"><a href="#Softening-è»ŸåŒ–" class="headerlink" title="Softening (è»ŸåŒ–)"></a>Softening (è»ŸåŒ–)</h4><h4 id="Merging-åˆä½µ"><a href="#Merging-åˆä½µ" class="headerlink" title="Merging (åˆä½µ)"></a>Merging (åˆä½µ)</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;äººå·¥æ™ºæ…§èˆ‡æ‡‰ç”¨ç­†è¨˜4&quot;&gt;&lt;a href=&quot;#äººå·¥æ™ºæ…§èˆ‡æ‡‰ç”¨ç­†è¨˜4&quot; class=&quot;headerlink&quot; title=&quot;äººå·¥æ™ºæ…§èˆ‡æ‡‰ç”¨ç­†è¨˜4&quot;&gt;&lt;/a&gt;äººå·¥æ™ºæ…§èˆ‡æ‡‰ç”¨ç­†è¨˜4&lt;/h1&gt;&lt;h2 id=&quot;ç¬¬å››å‘¨&quot;&gt;&lt;a href=&quot;#ç¬¬å››å‘¨&quot; class=&quot;header
      
    
    </summary>
    
      <category term="äººå·¥æ™ºæ…§èˆ‡æ‡‰ç”¨" scheme="https://caocharles.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E8%88%87%E6%87%89%E7%94%A8/"/>
    
    
      <category term="AI" scheme="https://caocharles.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>ç¬¬ä¸€å‘¨æ•™å­¸é€²åº¦</title>
    <link href="https://caocharles.github.io/%E7%AC%AC%E4%B8%80%E5%91%A8%E6%95%99%E5%AD%B8%E9%80%B2%E5%BA%A6/"/>
    <id>https://caocharles.github.io/ç¬¬ä¸€å‘¨æ•™å­¸é€²åº¦/</id>
    <published>2018-10-08T06:49:59.000Z</published>
    <updated>2018-10-08T06:49:59.491Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“(ç¬¬ä¸€å‘¨)</title>
    <link href="https://caocharles.github.io/%E9%80%B2%E9%9A%8E%E5%89%B5%E6%96%B0%E7%A7%91%E6%8A%80%E6%8A%80%E8%A1%93/"/>
    <id>https://caocharles.github.io/é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“/</id>
    <published>2018-09-26T02:38:16.000Z</published>
    <updated>2018-09-26T02:46:13.145Z</updated>
    
    <content type="html"><![CDATA[<h1 id="é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“å…±ç·¨-ç¬¬ä¸€å€‹ç¦®æ‹œ"><a href="#é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“å…±ç·¨-ç¬¬ä¸€å€‹ç¦®æ‹œ" class="headerlink" title="é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“å…±ç·¨(ç¬¬ä¸€å€‹ç¦®æ‹œ)"></a>é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“å…±ç·¨(ç¬¬ä¸€å€‹ç¦®æ‹œ)</h1><ul><li>æ¯å‘¨çš„éŒ„éŸ³æª”éƒ½æ”¾åœ¨é€™è£¡</li></ul><p><a href="https://drive.google.com/drive/folders/1jQl4cLGAwekYkz6gSCDlR7wwxA4dqbzP?usp=sharing" target="_blank" rel="noopener">https://drive.google.com/drive/folders/1jQl4cLGAwekYkz6gSCDlR7wwxA4dqbzP?usp=sharing</a></p><h2 id="æ›¾è€å¸«-è¦æ±‚"><a href="#æ›¾è€å¸«-è¦æ±‚" class="headerlink" title="æ›¾è€å¸« (è¦æ±‚)"></a>æ›¾è€å¸« (è¦æ±‚)</h2><ul><li>çˆ¬èŸ² PTTã€FB</li><li>ç‰¹å®šç¶²ç«™ (æ–‡ç« )</li><li>åƒè€ƒæ–‡ç» (æœ‰èˆˆè¶£çš„ä¸»é¡Œ)</li><li>è€å¸«åªæœ‰ä¸Šå…­é€±çš„èª²ç¨‹</li><li>æ–‡å­—åˆ†æç‚ºä¸» çµæ§‹åŒ–è³‡æ–™ä¹Ÿå¯ä»¥</li><li>Kagleã€æ”¿åºœçš„å…¬é–‹è³‡æ–™ã€Researched Data</li><li>å¾NLPä¸ŠçŸ¥é“å•†å“çš„è¡Œæƒ…</li><li>å°ˆå®¶ç³»çµ±æ˜¯ç”šéº¼?</li></ul><h2 id="ç¬¬ä¸€å‘¨"><a href="#ç¬¬ä¸€å‘¨" class="headerlink" title="ç¬¬ä¸€å‘¨"></a>ç¬¬ä¸€å‘¨</h2><ul><li>è¦å•¥çš„è³‡æ–™é›†ï¼ŒNLTK</li><li>ä¸€çµ„å ±ä¸€ç¯‡ NLP çš„ç ”ç©¶ã€è«–æ–‡ã€æ–‡ç»æ¢è¨</li><li>ä¸‹ç¦®æ‹œå°±å¯ä»¥åšé€™ä»¶äº‹</li><li>æˆ‘æœ‰éŒ„éŸ³å˜»å˜»</li><li>è‡­å™ç”·åšå£«ç”Ÿ(äººå®¶åªæ˜¯å¹´é½¡æ¯”è¼ƒå¤§ã„…â€¦) æˆ‘èªªç¦®æ‹œä¸€é‚£å€‹</li><li>HI-EXPEND æ˜¯å•¥æ„æ€ (èŠ±æ¯”è¼ƒå¤šéŒ¢ä¾†è®€æ›¸çš„äºº)</li><li>èªªå¾—å¥½ï¼Œæˆ‘è¯å±±æ´¾â€¦</li><li>è¦å¹¹å˜›<ul><li>èªæ„åˆ†æ</li><li>æƒ…æ„Ÿåˆ†æ</li><li>ç¶²è·¯è²é‡åˆ†æï¼Œéƒ½ä¸å®¹æ˜“</li></ul></li></ul><h3 id="Sources-of-Big-Data"><a href="#Sources-of-Big-Data" class="headerlink" title="Sources of Big Data"></a>Sources of Big Data</h3><ul><li><p>In addition to accumulation of traditional data of transactions:</p><ul><li><p>Data warehousing (è³‡æ–™å€‰å„²)</p></li><li><p>Cloud computing</p></li><li><p>Social network</p></li><li><p>Internet of Things (IOT)</p></li></ul></li><li><p>The business data volume is therefore increasing dramatically.</p></li><li><p>Some important attributes may be embedded in or mined from the big volume of data.</p></li><li><p>Therefore, data management issues for the big data are getting è¦å’ªæŒ–æ­Œçš„.</p></li></ul><h3 id="Common-Framework-of-Big-Data"><a href="#Common-Framework-of-Big-Data" class="headerlink" title="Common Framework of Big Data"></a>Common Framework of Big Data</h3><ul><li>å…­å€‹V(è‡ªå·±æŸ¥)<ul><li>Volume</li><li>Velocity</li><li>Variety</li><li>Veracity</li><li>Value</li><li>æ·±V</li></ul></li></ul><p><img src="https://i.imgur.com/dqC1lrY.png" alt=""></p><p><a href="https://i.imgur.com/U98MFAU.png" target="_blank" rel="noopener">æˆ‘çš„å¸¥ç…§</a>(å±å•¦)</p><h3 id="éç›£ç£å¼å­¸ç¿’"><a href="#éç›£ç£å¼å­¸ç¿’" class="headerlink" title="éç›£ç£å¼å­¸ç¿’"></a>éç›£ç£å¼å­¸ç¿’</h3><ul><li>ç‰›å¥¶è·Ÿå•¤é…’(é—œè¯å¼è³‡æ–™)- </li></ul><h3 id="ç›£ç£å¼å­¸ç¿’"><a href="#ç›£ç£å¼å­¸ç¿’" class="headerlink" title="ç›£ç£å¼å­¸ç¿’"></a>ç›£ç£å¼å­¸ç¿’</h3><ul><li>ä¸€ç”Ÿåªç£ä½ ä¸€äºº</li><li>æœ‰Yé‚£ä¸€æ¢çš„å¯ä»¥ç£</li><li>ç£çš„è¶Šæº–ã€è¶Šå¤¯(XGBOOSTã€DNN)</li><li>æ±ºç­–æ¨¹(Desision tree) (æœ€è€çš„é‚£ç¨®)</li></ul><h3 id="å¢å¼·å¼å­¸ç¿’"><a href="#å¢å¼·å¼å­¸ç¿’" class="headerlink" title="å¢å¼·å¼å­¸ç¿’"></a>å¢å¼·å¼å­¸ç¿’</h3><h3 id="æ·±åº¦å­¸ç¿’-é¡ç¥ç¶“ç¶²è·¯"><a href="#æ·±åº¦å­¸ç¿’-é¡ç¥ç¶“ç¶²è·¯" class="headerlink" title="æ·±åº¦å­¸ç¿’(é¡ç¥ç¶“ç¶²è·¯)"></a>æ·±åº¦å­¸ç¿’(é¡ç¥ç¶“ç¶²è·¯)</h3><h3 id="AIçš„ä¸‰å¤§æ‡‰ç”¨"><a href="#AIçš„ä¸‰å¤§æ‡‰ç”¨" class="headerlink" title="AIçš„ä¸‰å¤§æ‡‰ç”¨"></a>AIçš„ä¸‰å¤§æ‡‰ç”¨</h3><ul><li>èªè¨€è¾¨è­˜</li></ul><h3 id="Prescriptive-Analysis"><a href="#Prescriptive-Analysis" class="headerlink" title="Prescriptive Analysis"></a>Prescriptive Analysis</h3><ul><li>åè©:æŒ‡å°æ€§åˆ†æ</li><li>é‡‹ç¾©:æ ¹æ“šé æ¸¬åˆ†æçš„çµæœï¼Œç¸½çµåŠå»ºè­°ä¸åŒçµæœçš„å„ªåŒ–è¡Œå‹•ã€‚</li><li>æ–¹æ³•:é€éé æ¸¬åˆ†æçµæœï¼Œé€²è¡Œæ±ºç­–</li></ul><h3 id="NTLK-å¥½åƒé€™æ‰æ˜¯é‡é»"><a href="#NTLK-å¥½åƒé€™æ‰æ˜¯é‡é»" class="headerlink" title="NTLK (å¥½åƒé€™æ‰æ˜¯é‡é»)"></a>NTLK (å¥½åƒé€™æ‰æ˜¯é‡é»)</h3><ul><li>æ‰¾ä¸€ç¯‡paperä¾†å ±å‘Š</li><li><p><a href="https://textminingonline.com/dive-into-nltk-part-i-getting-started-with-nltk" target="_blank" rel="noopener">textminingonline.nltk</a></p></li><li><p>è¼‰ä¸€ä¸‹å¥—ä»¶</p></li><li><p><a href="https://www.nltk.org/install.html" target="_blank" rel="noopener">ç¶²é åœ¨é€™</a> è¼‰å¥½ä¹…</p></li></ul><p><img src="https://i.imgur.com/FiEFnmf.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># èªæ–™åº«åœ¨é€™</span></span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> brown</span><br><span class="line">brown.words()[<span class="number">0</span>:<span class="number">10</span>]</span><br><span class="line">brown.tagged_words()[<span class="number">0</span>:<span class="number">10</span>]</span><br><span class="line">len(brown.words())</span><br><span class="line">dir(brown)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ–·å¥</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ–·å­—</span></span><br><span class="line">tokens = word_tokenize(text)</span><br></pre></td></tr></table></figure><h3 id="Tokenizers"><a href="#Tokenizers" class="headerlink" title="Tokenizers"></a>Tokenizers</h3><ul><li>å¥½å¤šTokenï¼Œå¥½æƒ³ç©æ¡ŒéŠã€‚(å‚»çœ¼â€¦.)</li><li>Token -&gt; ç’€ç’¨å¯¶çŸ³<h3 id="ç¬¬ä¸‰å ‚èª²"><a href="#ç¬¬ä¸‰å ‚èª²" class="headerlink" title="ç¬¬ä¸‰å ‚èª²"></a>ç¬¬ä¸‰å ‚èª²</h3></li><li><p>Part-Of-Speech Tagging-1 </p><ul><li>æœ€é‡è¦çš„æ–‡å­—åˆ†æä¹‹ä¸€</li><li>â€¦æŠ•å½±ç‰‡éƒ½æœ‰(ä¹Ÿæ˜¯)</li></ul></li><li><p>Part of speech tagging-2</p><ul><li>.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> treebank</span><br><span class="line">len(treebank.tagged_sents())</span><br><span class="line">train_data = treebank.tagged_sents()[:<span class="number">3000</span>]</span><br><span class="line">print(train_data)</span><br><span class="line">test_data = treebank.tagged_sents()[<span class="number">3000</span>:]</span><br><span class="line">print(test_data)</span><br></pre></td></tr></table></figure><p>ç«Ÿèƒ½å¦‚æ­¤å„ªç§€ &lt;3(è¬æ±æ£®)</p><h3 id="åŠ©æ•™ç²¾è¯-èº«æè·ŸæŸé¾ä¸€æ¨£-é‚„è »å¯æ„›çš„"><a href="#åŠ©æ•™ç²¾è¯-èº«æè·ŸæŸé¾ä¸€æ¨£-é‚„è »å¯æ„›çš„" class="headerlink" title="åŠ©æ•™ç²¾è¯(èº«æè·ŸæŸé¾ä¸€æ¨£)é‚„è »å¯æ„›çš„"></a>åŠ©æ•™ç²¾è¯(èº«æè·ŸæŸé¾ä¸€æ¨£)é‚„è »å¯æ„›çš„</h3><ul><li>éœ€è¦åŠ å…¥è¨˜æ†¶çš„çµæ§‹</li><li>è£å‚™å¾ˆé‡è¦å— ?<ul><li>â€¦</li><li>â€¦</li></ul></li><li>åŠ©æ•™é™¤äº†è²éŸ³æª”éƒ½å¯ä»¥å¹«æˆ‘å€‘çˆ¬</li><li>æŸé¾æƒ³æŠ“AVå¥³å„ªåœ–(ä¹¾æˆ‘é—¢æ˜¯)</li><li>è¡¨ç‰¹ç‰ˆæŠ“åœ–(æˆ‘å¥½åƒæœ‰æŠ“é) æˆ‘æŠ“éè¥¿æ–¯&lt;3(æƒ³è¦++) (å¤ªè®šå•¦~)<ul><li><a href="https://hackmd.io/6RIZ7tcyRymbihSUfCyIEw?view" target="_blank" rel="noopener">https://hackmd.io/6RIZ7tcyRymbihSUfCyIEw?view</a></li></ul></li><li>åŠ©æ•™å‰›å‰›èªªç”šéº¼æ¨¡å‹æ˜¯æœ€å·®çš„ ?</li><li>å®¹æ˜“éåº¦é…é£¾çš„æ¨¡å‹å¾ˆå·®(æ‡‰è©²å§)(é©æ‹‰å¹¹)</li><li>87è¬å¼µåœ–(å¥½çŒ›)è®Šæˆ8è¬å¼µè€Œå·²</li><li>æ„Ÿè¦ºå°±è·ŸAIç›¸æ©Ÿä¸€æ¨£</li><li>æ··æ·†çŸ©é™£(åˆ°åº•æœƒä¸æœƒé€²è¤‡è³½å‘¢~å¥½åˆºæ¿€)</li></ul><h3 id="ä¸€å€‹å°è©±æ©Ÿå™¨äºº"><a href="#ä¸€å€‹å°è©±æ©Ÿå™¨äºº" class="headerlink" title="ä¸€å€‹å°è©±æ©Ÿå™¨äºº"></a>ä¸€å€‹å°è©±æ©Ÿå™¨äºº</h3><ol><li>AI is A Brandâ€™s New Face</li><li>Mind the tech Details</li><li>Know the difference between conversation AI and conventional chatbots</li><li>Integrate Key Data Sets</li></ol><h3 id="Crawler-amp-Data-Cleanup"><a href="#Crawler-amp-Data-Cleanup" class="headerlink" title="Crawler &amp; Data Cleanup"></a>Crawler &amp; Data Cleanup</h3><p>1.çˆ¬èŸ²ï¼Œéš¨æ©ŸæŠ½è³‡æ–™<br>2.æ¡ç”¨Python packagesæˆ– BASH shellsçš†å¯<br>3.å¯¦é©—å®¤æœ‰PTTçš„çˆ¬èŸ²è³‡æ–™<br>4.å»ºè­°å…ˆå­¸ç¿’åŸºæœ¬linuxæŒ‡ä»¤<br>5.é«˜é »å­—èˆ‡ä½é »å­—ï¼Œéƒ½æ¯”ä¸ä¸Šå¯ä»¥æ¸…ç†å› ç´ çš„å­—</p><h3 id="çµè«–"><a href="#çµè«–" class="headerlink" title="çµè«–"></a>çµè«–</h3><ul><li>å¹¸å¥½é‚„æœ‰åŠ©æ•™â€¦</li><li>æœ‰äººæƒ³è·Ÿåšç­ä¸€çµ„ã„‡</li><li>æˆ‘å€‘å››å€‹ä¸€çµ„ä¸æ˜¯å—</li><li>NLPçš„æ–‡ç« (è¦æ‰¾å•¥)-å„è‡ªæ‰¾åœ¨æ··ä¸€æ³¢å—</li><li>ç”¢å“çš„è²é‡(ä¸Šæ¸¸ä¸å¤ªçŸ¥é“é€šè·¯è³¼è²·çš„æ¶ˆè²»è€…è³‡æ–™)</li><li>topical model</li><li>æˆ‘çš„é®®å¥¶èŒ¶æ©Ÿå™¨äºº</li></ul><h3 id="ä¸‹ç¦®æ‹œçš„ä½œæ¥­"><a href="#ä¸‹ç¦®æ‹œçš„ä½œæ¥­" class="headerlink" title="ä¸‹ç¦®æ‹œçš„ä½œæ¥­"></a>ä¸‹ç¦®æ‹œçš„ä½œæ¥­</h3><ul><li>æ‰¾å‡ºåˆ†æNLPçš„æ–¹æ³•å— ?</li><li>æˆ‘å…ˆè®€æ±æ£®èªªçš„é‚£å…©ç¯‡ï¼Œä¸€äº›å°æ‘˜è¦ã€å¿ƒå¾—å’Œ murmur è¨˜éŒ„åœ¨<a href="https://hackmd.io/XT1NAWXDT8KwmPgdO2gfIg" target="_blank" rel="noopener">é€™é‚Š</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“å…±ç·¨-ç¬¬ä¸€å€‹ç¦®æ‹œ&quot;&gt;&lt;a href=&quot;#é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“å…±ç·¨-ç¬¬ä¸€å€‹ç¦®æ‹œ&quot; class=&quot;headerlink&quot; title=&quot;é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“å…±ç·¨(ç¬¬ä¸€å€‹ç¦®æ‹œ)&quot;&gt;&lt;/a&gt;é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“å…±ç·¨(ç¬¬ä¸€å€‹ç¦®æ‹œ)&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;æ¯å‘¨çš„éŒ„éŸ³æª”
      
    
    </summary>
    
      <category term="é€²éšå‰µæ–°ç§‘æŠ€æŠ€è¡“" scheme="https://caocharles.github.io/categories/%E9%80%B2%E9%9A%8E%E5%89%B5%E6%96%B0%E7%A7%91%E6%8A%80%E6%8A%80%E8%A1%93/"/>
    
    
      <category term="Pytorch" scheme="https://caocharles.github.io/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>çµ±ç ”æ·±åº¦å­¸ç¿’è®€æ›¸æœƒ</title>
    <link href="https://caocharles.github.io/%E7%B5%B1%E7%A0%94%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E8%AE%80%E6%9B%B8%E6%9C%83/"/>
    <id>https://caocharles.github.io/çµ±ç ”æ·±åº¦å­¸ç¿’è®€æ›¸æœƒ/</id>
    <published>2018-09-20T15:43:20.000Z</published>
    <updated>2018-09-26T02:31:58.205Z</updated>
    
    <content type="html"><![CDATA[<h2 id="è®€æ›¸æœƒç°¡ä»‹"><a href="#è®€æ›¸æœƒç°¡ä»‹" class="headerlink" title="è®€æ›¸æœƒç°¡ä»‹"></a>è®€æ›¸æœƒç°¡ä»‹</h2><p>å¤§å®¶å¥½ï¼Œé€™æ˜¯æˆ‘å’Œç«‹è«­ç™¼èµ·çš„è®€æ›¸æœƒï¼Œé€™å€‹è®€æ›¸æœƒçš„ç›®çš„æ˜¯å¸Œæœ›é€éè¨è«–åŠåˆ†äº«ä¾†å­¸ç¿’Machine Learning + Deep Learningï¼Œå¸Œæœ›å¤§å®¶ä»¥å¾Œä¸è¦å¤±æ¥­(ä¾†è‡ªæ±æ£®çš„æé†’)</p><h2 id="å…ˆå‚™çŸ¥è­˜"><a href="#å…ˆå‚™çŸ¥è­˜" class="headerlink" title="å…ˆå‚™çŸ¥è­˜"></a>å…ˆå‚™çŸ¥è­˜</h2><ul><li>å¾®ç©åˆ†(å¾®åˆ†å§)</li><li>ç·šæ€§ä»£æ•¸(å‘é‡è¼¸å…¥å¾Œçš„å‚³å°åŠé‹ç®—)</li></ul><p>æˆ‘å€‘é€™å­¸å¹´çš„é€²åº¦å¤§è‡´ç°¡å–®ä»‹ç´¹å¦‚ä¸‹(æš«å®š)</p><h2 id="ä¸Šå­¸æœŸ"><a href="#ä¸Šå­¸æœŸ" class="headerlink" title="ä¸Šå­¸æœŸ"></a>ä¸Šå­¸æœŸ</h2><ul><li>ä¸€é–‹å§‹å…ˆå¸¶å¤§å®¶å…¥é–€ç¨‹å¼ï¼Œä½†é‚„ä¸ç¢ºå®šè¦å¾ Keras æˆ–æ˜¯ TensorFlow å…¥æ‰‹</li><li>ä¹‹å¾Œå¤§å®¶å°±æ¯å‘¨åšå€‹ä½œæ¥­ï¼Œç„¶å¾Œä¹Ÿè¦çœ‹å€‹èª²ç¨‹</li><li>èª²ç¨‹æ–¹é¢æ‡‰è©²ä»¥æå®æ¯…çš„ Machine Learing ç‚ºä¸»ï¼Œä»–çš„èª²æœ‰ä»¥ä¸‹ç‰¹é»<ul><li>å¼·èª¿ç„¡ç—›å…¥é–€ï¼Œè€Œä¸”æ¶‰åŠçš„é ˜åŸŸå¾ˆå»£ï¼Œåœ–åƒåŠèªéŸ³è¾¨è­˜ã€èªæ„åˆ†æç­‰ç­‰</li><li>ä¸Šèª²æ–¹å¼æœ‰è¶£ï¼ŒåŸºæœ¬ä¸Šä¸æœƒæœ‰æ¯ç‡¥çš„æ„Ÿè¦º</li><li>æ›´é‡è¦çš„æ˜¯æè€å¸«ä¸Šèª²è¬›çš„éƒ½æ˜¯å¾ˆæ–°çš„å…§å®¹ï¼Œç¸½ä¹‹å…¥é–€çœŸçš„æ¨è–¦</li></ul></li><li>å¯¦ä½œæ–¹é¢çš„è³‡æºå¾ˆå¤šï¼Œå†æ…¢æ…¢ä»‹ç´¹</li><li>å¤§å®¶æœ‰æ™‚é–“çš„è©±å¯ä»¥å ±åä¸€äº›æ¯”è³½ï¼Œä¾‹å¦‚é»‘å…‹æ¾æˆ–æ˜¯ Kaggle </li><li>è¨è«–å¯¦ä½œä¸Šçš„æŠ€å·§ã€è§€å¿µåŠå•é¡Œ</li><li>Scikit-Learn (æ©Ÿå™¨å­¸ç¿’ ML å¥—ä»¶)ï¼Œæ¯”è¼ƒæ¬¡è¦ï¼Œ<br>ä½†é‚„æ˜¯å¸Œæœ›å¤§å®¶èƒ½å¤§è‡´äº†è§£ï¼Œä¸‹å­¸æœŸçš„å¤šè®Šé‡æœƒè¼•é¬†è¨±å¤š</li></ul><h2 id="å¯’å‡"><a href="#å¯’å‡" class="headerlink" title="å¯’å‡"></a>å¯’å‡</h2><p>å¯’å‡å¤§å®¶å¯èƒ½å¾ˆå¿™ï¼Œä½†å¸Œæœ›å¤§å®¶é‚„æ˜¯èƒ½æ’¥é»æ™‚é–“çœ‹äº›ç›¸é—œçš„æ±è¥¿</p><ul><li>æ—è»’ç”°çš„æ©Ÿå™¨å­¸ç¿’åŸºçŸ³è·ŸæŠ€æ³•<ul><li>è »ç†è«–çš„ä¸éå¤§å®¶æ˜¯ç¢©å£«æœƒç†è«–æ‡‰è©²çš„æ‰€ä»¥é‚„æ˜¯ç¡¬è‘—é ­çš®çœ‹å§</li><li>è¬›çš„æ±è¥¿å…¶å¯¦éƒ½è »åŸå§‹çš„ï¼Œæœ‰äº›æ±è¥¿å…¶å¯¦å·²ç¶“æ²’äººåœ¨ç”¨äº†</li><li>ä½†æ˜¯èµ·æºçš„æ±è¥¿æˆ‘è¦ºå¾—è½ä¸€è½å¤šå°‘æœƒæœ‰å¹«åŠ©</li><li>å¯èƒ½æœƒè½åˆ°å´©æ½°ï¼Œæ‡‰è©²æ˜¯æˆ‘å¤ªç¬¨(å¯èƒ½åªæœ‰AIçœŸæ­£æ‡‚)</li><li>è½èªªå…¶å¯¦ä½œæ¥­è¶…çˆ†é›£(by è³‡ç§‘-åŠ‰æ˜­éºŸæ•™æˆ)</li><li>ä½†æ˜¯å¤§å®¶ä¹Ÿä¸ç”¨å¯«ä½œæ¥­ï¼Œå°±å¤§å®¶è‡ªå·±çœ‹ä¸€çœ‹å°±å¥½(å§)</li></ul></li></ul><h2 id="ä¸‹å­¸æœŸ"><a href="#ä¸‹å­¸æœŸ" class="headerlink" title="ä¸‹å­¸æœŸ"></a>ä¸‹å­¸æœŸ</h2><p>ç¢©ä¸€ä¸‹èª²æ¥­æœƒæŒºé‡çš„ï¼Œä½†å¥½åƒä¹Ÿé‚„å¥½ï¼Œ<br>å¤šè®Šé‡é€™é–€èª²å¦‚æœä¸Šå­¸æœŸæœ‰åœ¨è®€æ›¸æœƒå­¸åˆ°æ±è¥¿å…¶å¯¦æ‡‰è©²æœƒè »è¼•é¬†çš„</p><ul><li>è«–æ–‡æ¢è¨ï¼Œå¦‚æœæ˜¯å¾ˆæ–°çš„å¸Œæœ›æˆ‘å€‘èƒ½æŠŠå®ƒå¯¦ä½œå‡ºä¾†çœ‹çœ‹</li><li>æœŸæœ›å¤§å®¶æœ‰æ‰¾åˆ°è‡ªå·²æƒ³åšçš„é …ç›®ï¼Œæˆ‘å€‘å¾ˆæ¨‚æ„ä¸€èµ·è¨è«–æˆ–æ˜¯æä¾›å¹«åŠ©ï¼Œ<br>æœ€å¥½çš„æƒ…æ³æ˜¯ä½ å€‘å¯ä»¥æŒ‡å°æˆ‘å€‘å˜»å˜»</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;è®€æ›¸æœƒç°¡ä»‹&quot;&gt;&lt;a href=&quot;#è®€æ›¸æœƒç°¡ä»‹&quot; class=&quot;headerlink&quot; title=&quot;è®€æ›¸æœƒç°¡ä»‹&quot;&gt;&lt;/a&gt;è®€æ›¸æœƒç°¡ä»‹&lt;/h2&gt;&lt;p&gt;å¤§å®¶å¥½ï¼Œé€™æ˜¯æˆ‘å’Œç«‹è«­ç™¼èµ·çš„è®€æ›¸æœƒï¼Œé€™å€‹è®€æ›¸æœƒçš„ç›®çš„æ˜¯å¸Œæœ›é€éè¨è«–åŠåˆ†äº«ä¾†å­¸ç¿’Machine Learning + D
      
    
    </summary>
    
      <category term="è®€æ›¸æœƒ" scheme="https://caocharles.github.io/categories/study-group/"/>
    
    
      <category term="Deep Learning" scheme="https://caocharles.github.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¸ç¿’</title>
    <link href="https://caocharles.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/"/>
    <id>https://caocharles.github.io/æ·±åº¦å­¸ç¿’/</id>
    <published>2018-08-28T16:12:21.000Z</published>
    <updated>2018-09-04T14:30:28.686Z</updated>
    
    <content type="html"><![CDATA[<h2 id="é¡ç¥ç¶“ç¶²è·¯-æ­·å²"><a href="#é¡ç¥ç¶“ç¶²è·¯-æ­·å²" class="headerlink" title="é¡ç¥ç¶“ç¶²è·¯ æ­·å²"></a>é¡ç¥ç¶“ç¶²è·¯ æ­·å²</h2><p>äººå·¥æ™ºæ…§æœ€æ—©å‡ºç¾æ–¼1950å¹´ä»£ã€‚äººå·¥æ™ºæ…§çš„ç›®æ¨™æ˜¯å¸Œæœ›èƒ½è®“é›»è…¦åƒäººä¸€ç­æ€è€ƒèˆ‡å­¸ç¿’ã€‚è¢«è¦–ç‚ºäººå·¥æ™ºæ…§ä¹‹çˆ¶çš„åœ–éˆ(Alan Mathison Turing)ï¼Œæå‡ºäº†æœ‰åçš„åœ–éˆæ¸¬è©¦:äººé¡èˆ‡æ©Ÿå™¨å°è©±ï¼Œå¦‚æœäººé¡ç„¡æ³•æ ¹æ“šé€™äº›å°è©±éç¨‹åˆ¤æ–·å°æ–¹æ˜¯äººæˆ–æ©Ÿå™¨ï¼Œå³é€šéæ¸¬è©¦ï¼Œèªç‚ºé€™å°é›»è…¦å…·æœ‰äººå·¥æ™ºæ…§ã€‚</p><p>éš¨è‘—AIçš„ç™¼å±•æ—¥ç›ŠèŒå£¯ï¼Œ1980å¹´ä»£(Jhon Searle)ï¼Œæå‡ºäº†å°äººå·¥æ™ºæ…§çš„åˆ†é¡æ–¹å¼:</p><ul><li><p>å¼·äººå·¥æ™ºæ…§(Strong AI) : æ©Ÿå™¨èˆ‡äººå…·æœ‰å®Œæ•´çš„èªçŸ¥èƒ½åŠ›ã€‚</p></li><li><p>å¼±äººå·¥æ™ºæ…§(Weak AI) : æ©Ÿå™¨è¨­è¨ˆçœ‹èµ·ä¾†å…·æœ‰æ™ºæ…§å³å¯ã€‚</p></li></ul><p>è€Œæ·±åº¦å­¸ç¿’æ˜¯äººå·¥æ™ºæ…§ä¸­ï¼Œç¾ä»Šæˆé•·æœ€å¿«çš„é ˜åŸŸï¼Œéš¨è‘—é›»è…¦çš„æ™®åŠä»¥åŠå…¶CPUã€GPUé‹ç®—èƒ½åŠ›å¢å¼·ï¼Œæˆ‘å€‘å¯ä»¥é€éä¸–ç•Œä¸Šå„å€‹è³‡æ–™åº«æ”¶é›†å¤§é‡è³‡æ–™ï¼Œå°‡è³‡æ–™æ•´ç†æˆé¡ç¥ç¶“ç¶²è·¯çš„æ ¼å¼ï¼Œè—‰ç”±æ¨¡æ“¬äººé¡ç¥ç¶“ç¶²è·¯çš„é‹ä½œæ–¹å¼ï¼ŒåŠ ä¸Šæ•¸å­¸çš„æ¼”ç®—æ³•é€²è¡Œæ›´æ–°åƒæ•¸ï¼Œå°±å¯ä»¥è®“é›»è…¦å­¸ç¿’åˆ†è¾¨æ—¥å¸¸ç”Ÿæ´»çš„äº‹ç‰©ï¼Œå¸¸è¦‹çš„æ·±åº¦å­¸ç¿’æ¶æ§‹ï¼Œå¦‚å¤šå±¤æ„ŸçŸ¥å™¨MLPã€æ·±åº¦ç¥ç¶“ç¶²è·¯DNNã€å·ç©ç¥ç¶“ç¶²è·¯CNNã€éè¿´ç¥ç¶“ç¶²è·¯RNNã€‚</p><p>è€Œé€™äº›æ·±åº¦å­¸ç¿’çš„æ¶æ§‹æ‡‰ç”¨åœ¨è¦–è¦ºè¾¨è­˜ã€èªéŸ³è¾¨è­˜ã€è‡ªç„¶èªè¨€è™•ç†ã€ç”Ÿç‰©é†«å­¸ç­‰é ˜åŸŸï¼Œçš†æœ‰éå¸¸å¥½çš„æ•ˆæœã€‚</p><p><img src="https://i.imgur.com/5BFVrX2.png" alt=""></p><p>äººå·¥æ™ºæ…§ç¾åœ¨å·²å»£æ³›é‹ç”¨åœ¨æˆ‘å€‘çš„æ—¥å¸¸ç”Ÿæ´»ä¹‹ä¸­ï¼Œåƒæ˜¯æ‰‹å¯«è¾¨è­˜ã€åœ–åƒè¾¨è­˜ã€èªéŸ³è¾¨è­˜ï¼Œå¹¾ä¹éƒ½å­˜åœ¨æ–¼äººæ‰‹ä¸€å°çš„æ‰‹æ©Ÿä¹‹ä¸­ï¼Œé‚„æœ‰æ›´é€²ä¸€æ­¥çš„é‹ç”¨ï¼Œå¦‚è‡ªå‹•é§•é§›ï¼Œé€éç¡¬é«”ä¸Šçš„æ›´æ–°ï¼Œæˆ‘å€‘å¯ä»¥è£è¨­æ„Ÿæ¸¬å™¨æ„Ÿæ‡‰è»Šå­å‘¨åœçš„ç’°å¢ƒç‹€æ³ï¼ŒåŠ ä¸Šåœ–åƒè¾¨è­˜ï¼Œä¸¦æ•´åˆæˆè³‡è¨Šè®“é›»è…¦åˆ¤æ–·æ˜¯å¦åœè»Šæˆ–ç¹¼çºŒè¡Œé§›ï¼Œé€éæ¼”ç®—æ³•è®“é›»è…¦çŸ¥é“è©²å¦‚ä½•åšæ±ºå®šï¼Œåˆ°æœ€å¾Œå°‡æœƒå¯¦ç¾åœ¨å¸‚å€è¡Œé§›ä¹‹ä¸­ï¼Œéš¨è‘—ç§‘æŠ€è¶Šä¾†è¶Šé€²æ­¥ï¼Œæ·±åº¦å­¸ç¿’æ‰€æ‡‰ç”¨çš„é ˜åŸŸå°±è¶Šä¾†è¶Šå»£ã€‚</p><h2 id="é¡ç¥ç¶“ç¶²è·¯-ç°¡ä»‹"><a href="#é¡ç¥ç¶“ç¶²è·¯-ç°¡ä»‹" class="headerlink" title="é¡ç¥ç¶“ç¶²è·¯ ç°¡ä»‹"></a>é¡ç¥ç¶“ç¶²è·¯ ç°¡ä»‹</h2><p>[ç¶­åŸºç™¾ç§‘]</p><p>é¡ç¥ç¶“ç¶²è·¯ç°¡ç¨±ï¼ˆè‹±èªï¼šArtificial Neural Networkï¼ŒANNï¼‰ï¼Œç°¡ç¨±<strong>ç¥ç¶“ç¶²è·¯</strong>ï¼ˆNeural Networkï¼ŒNNï¼‰æˆ–<strong>é¡ç¥ç¶“ç¶²è·¯</strong>ï¼Œåœ¨æ©Ÿå™¨å­¸ç¿’å’ŒèªçŸ¥ç§‘å­¸é ˜åŸŸï¼Œæ˜¯ä¸€ç¨®æ¨¡ä»¿ç”Ÿç‰©ç¥ç¶“ç¶²è·¯ï¼ˆå‹•ç‰©çš„ä¸­æ¨ç¥ç¶“ç³»çµ±ï¼Œç‰¹åˆ¥æ˜¯å¤§è…¦ï¼‰çš„çµæ§‹å’ŒåŠŸèƒ½çš„æ•¸å­¸æ¨¡å‹æˆ–è¨ˆç®—æ¨¡å‹ï¼Œç”¨æ–¼å°å‡½å¼é€²è¡Œä¼°è¨ˆæˆ–è¿‘ä¼¼ã€‚ç¥ç¶“ç¶²è·¯ç”±å¤§é‡çš„äººå·¥ç¥ç¶“å…ƒè¯çµé€²è¡Œè¨ˆç®—ã€‚å¤§å¤šæ•¸æƒ…æ³ä¸‹äººå·¥ç¥ç¶“ç¶²è·¯èƒ½åœ¨å¤–ç•Œè³‡è¨Šçš„åŸºç¤ä¸Šæ”¹è®Šå…§éƒ¨çµæ§‹ï¼Œæ˜¯ä¸€ç¨®è‡ªé©æ‡‰ç³»çµ±ï¼Œé€šä¿—çš„è¬›å°±æ˜¯å…·å‚™å­¸ç¿’åŠŸèƒ½ã€‚</p><p>ç¾ä»£ç¥ç¶“ç¶²è·¯æ˜¯ä¸€ç¨®éç·šæ€§çµ±è¨ˆæ€§è³‡æ–™å»ºæ¨¡å·¥å…·ã€‚å…¸å‹çš„ç¥ç¶“ç¶²è·¯å…·æœ‰ä»¥ä¸‹ä¸‰å€‹éƒ¨åˆ†ï¼š</p><ul><li><p><strong>çµæ§‹</strong>ï¼ˆ<strong>Architecture</strong>ï¼‰<br>çµæ§‹æŒ‡å®šäº†ç¶²è·¯ä¸­çš„è®Šæ•¸å’Œå®ƒå€‘çš„æ‹“æ’²é—œä¿‚ã€‚<br>ä¾‹å¦‚:ç¥ç¶“ç¶²è·¯ä¸­çš„è®Šæ•¸å¯ä»¥æ˜¯ç¥ç¶“å…ƒé€£æ¥çš„æ¬Šé‡ï¼ˆweightsï¼‰å’Œç¥ç¶“å…ƒçš„æ¿€å‹µå€¼ï¼ˆactivities of the neuronsï¼‰ã€‚</p></li><li><p><strong>æ¿€å‹µå‡½å¼ï¼ˆActivity Ruleï¼‰</strong><br>å¤§éƒ¨åˆ†ç¥ç¶“ç¶²è·¯æ¨¡å‹å…·æœ‰ä¸€å€‹çŸ­æ™‚é–“å°ºåº¦çš„å‹•åŠ›å­¸è¦å‰‡ï¼Œä¾†å®šç¾©ç¥ç¶“å…ƒå¦‚ä½•æ ¹æ“šå…¶ä»–ç¥ç¶“å…ƒçš„æ´»å‹•ä¾†æ”¹è®Šè‡ªå·±çš„æ¿€å‹µå€¼ã€‚ä¸€èˆ¬æ¿€å‹µå‡½å¼ä¾è³´æ–¼ç¶²è·¯ä¸­çš„æ¬Šé‡ï¼ˆå³è©²ç¶²è·¯çš„åƒæ•¸ï¼‰ã€‚</p></li></ul><ul><li><strong>å­¸ç¿’è¦å‰‡ï¼ˆLearning Ruleï¼‰</strong><br>å­¸ç¿’è¦å‰‡æŒ‡å®šäº†ç¶²è·¯ä¸­çš„æ¬Šé‡å¦‚ä½•éš¨è‘—æ™‚é–“æ¨é€²è€Œèª¿æ•´ã€‚</li></ul><p><img src="https://i.imgur.com/Gmo3LfJ.png" alt=""></p><p>ä¸Šåœ–ç‚ºä¸€å€‹ç°¡å–®çš„å¤šå±¤æ„ŸçŸ¥å™¨ï¼Œæˆ‘å€‘åˆ©ç”¨é€™å€‹ç¶²è·¯</p><h2 id="é¡ç¥ç¶“ç¶²è·¯-æ‡‰ç”¨"><a href="#é¡ç¥ç¶“ç¶²è·¯-æ‡‰ç”¨" class="headerlink" title="é¡ç¥ç¶“ç¶²è·¯ æ‡‰ç”¨"></a>é¡ç¥ç¶“ç¶²è·¯ æ‡‰ç”¨</h2><p><img src="https://i.imgur.com/ZK2OR9D.png" alt=""></p><p>æ‡‰ç”¨</p><ul><li><p>æ‰‹å¯«è¾¨è­˜</p><p>  åˆ©ç”¨Pythonä¸‹tensorflowæ¨¡çµ„ä¸­çš„MNISTè³‡æ–™ï¼Œæ”¶é›†äº†æ•¸è¬ç­†æƒæéçš„åœ–æª”åŠæ¨™ç±¤ï¼Œæˆ‘å€‘å¯ä»¥åˆ©ç”¨å„ç¨®é¡ç¥ç¶“ç¶²è·¯æ¨¡å‹å»ºç«‹åˆ†é¡å™¨æ¨¡å‹ï¼Œä¾æ“šæ¨¡å‹çš„ç‰¹æ€§åŠ ä»¥è¨“ç·´ï¼Œä¸¦å¯å°‡è¨“ç·´éçš„æ¨¡å‹å„²å­˜ï¼Œç”¨ä¾†é æ¸¬æ‰‹å¯«æ¿ä¸Šçš„æ•¸å­—ã€‚</p></li><li><p>åœ–åƒè¾¨è­˜</p><p>  ç¾ä»Šé›»è…¦è¾¨è­˜ä¸€èˆ¬çš„åœ–ç‰‡å·²ç¶“ç­‰åŒæ–¼äººé¡çš„è¾¨è­˜ç‡ï¼Œç”šè‡³åœ¨åæ‡‰çš„é€Ÿåº¦ä¸Šæœƒè¶…éäººé¡ï¼Œä½†åœ¨å‹•æ…‹å½±åƒçš„è¾¨è­˜åº¦é‚„æœ‰åŠ å¼·çš„ç©ºé–“ï¼Œé€éå„ç¨®æ¼”ç®—æ³•çš„æ¸¬è©¦èˆ‡æ”¹é€²ï¼Œæœ€çµ‚å°‡æœƒæ‡‰ç”¨åœ¨è‡ªå‹•é§•é§›ç­‰æ‡‰ç”¨ä¸Šã€‚ </p></li><li><p>è‡ªç„¶èªè¨€è™•ç†</p><p>  è‡ªç„¶èªè¨€(Nature Language Processing, NLP)ï¼Œæ˜¯è®“é›»è…¦å­¸ç¿’ç†è§£äººé¡æ‰€èªªçš„è©±èªèˆ‡æ–‡å­—ï¼Œé€éåˆ†æè©æ€§ï¼Œè¨ˆç®—å…¶è©å‘é‡ç­‰ç­‰ï¼Œä¸¦é‹ç”¨æ¨¸ç´ è²æ°åˆ†é¡å™¨å°‡å¥å­åˆ†é¡ï¼Œä¾†åˆ†ææ—¥å¸¸å°è©±çš„å«æ„ï¼Œå…¶ç”¢å‡ºæœ‰ç¾åœ¨ç†±é–€çš„èŠå¤©æ©Ÿå™¨äººåŠFBæ‰€æä¾›çš„(Facebook Messenger Platform)å’Œlineæ‰€æ¨å‡ºçš„(Messaging API)ã€‚</p></li></ul><p><img src="https://i.imgur.com/Lc1XSE5.png" alt=""></p><p>AIèˆ‡å¤§æ•¸æ“šçš„æ‡‰ç”¨åªæœƒè¶Šä¾†è¶Šæ·±ã€è¶Šä¾†è¶Šå»£ã€è¶Šä¾†è¶Šå¿«ï¼Œåªè¦å°ç§‘æŠ€ç™¼å±•æœ‰èˆˆè¶£çš„äººï¼Œå°±å¯ä»¥è¸å…¥é€™å¡Šé ˜åŸŸäº†è§£AIçš„å‰å¤§ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;é¡ç¥ç¶“ç¶²è·¯-æ­·å²&quot;&gt;&lt;a href=&quot;#é¡ç¥ç¶“ç¶²è·¯-æ­·å²&quot; class=&quot;headerlink&quot; title=&quot;é¡ç¥ç¶“ç¶²è·¯ æ­·å²&quot;&gt;&lt;/a&gt;é¡ç¥ç¶“ç¶²è·¯ æ­·å²&lt;/h2&gt;&lt;p&gt;äººå·¥æ™ºæ…§æœ€æ—©å‡ºç¾æ–¼1950å¹´ä»£ã€‚äººå·¥æ™ºæ…§çš„ç›®æ¨™æ˜¯å¸Œæœ›èƒ½è®“é›»è…¦åƒäººä¸€ç­æ€è€ƒèˆ‡å­¸ç¿’ã€‚è¢«è¦–ç‚ºäººå·¥æ™º
      
    
    </summary>
    
      <category term="æ·±åº¦å­¸ç¿’" scheme="https://caocharles.github.io/categories/deep-learning/"/>
    
    
      <category term="Deep Learning" scheme="https://caocharles.github.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>EMæ¼”ç®—æ³•</title>
    <link href="https://caocharles.github.io/EM%E6%BC%94%E7%AE%97%E6%B3%95/"/>
    <id>https://caocharles.github.io/EMæ¼”ç®—æ³•/</id>
    <published>2018-08-28T09:31:35.000Z</published>
    <updated>2018-09-10T04:33:56.835Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/1121509ac1dc" target="_blank" rel="noopener">åƒè€ƒç¶²å€</a><br><a href="http://web.mit.edu/6.435/www/Dempster77.pdf" target="_blank" rel="noopener">Maximum Likelihood from Incomplete Data via the EM Algorithm</a></p><hr><p><strong>æœ€å¤§æœŸæœ›æ¼”ç®—æ³•</strong>ï¼ˆ<strong>Expectation-maximization algorithm</strong>ï¼Œåˆç¨±<strong>æœŸæœ›æœ€å¤§åŒ–ç®—æ³•</strong>ï¼‰<br>åœ¨è³‡æ–™åˆ†æä¸­å¸¸ç”¨æ–¼åˆ†ç¾¤ï¼Œåœ¨çµ¦å®šç¾¤æ•¸åŠæ©Ÿç‡æ¨¡å‹ä¸‹ï¼Œå»å°‹æ‰¾è§€æ¸¬å€¼è®Šæ•¸é–“çš„æ‰€éš±è—çš„è¨Šæ¯ï¼Œå¯ç”¨æ­¤æ¼”ç®—æ³•ä¾†ä¼°è¨ˆæ©Ÿç‡æ¨¡å‹ä¸­çš„åƒæ•¸ä¼°è¨ˆæˆ–éºå¤±å€¼å¡«è£œã€‚</p><hr><h2 id="åè©ä»‹ç´¹"><a href="#åè©ä»‹ç´¹" class="headerlink" title="åè©ä»‹ç´¹"></a>åè©ä»‹ç´¹</h2><ul><li><p>æ¨£æœ¬: $x$</p></li><li><p>æ¦‚ä¼¼å‡½æ•¸:  $L(\theta|x)=p(x|\theta)$</p></li><li><p>ç›®çš„: æ‰¾åˆ°èƒ½è®“ $L(\theta|x)$ æœ€å¤§åŒ–çš„åƒæ•¸</p></li></ul><p>æˆ‘çš„æƒ³æ³•å°±æ˜¯æ‰¾åˆ°ç¬¦åˆæˆ‘å€‘æ¨£æœ¬è³‡æ–™çš„â€æœ€å¤§â€æ¦‚ä¼¼å‡½æ•¸çš„æ©Ÿç‡æ¨¡å‹åƒæ•¸ï¼Œ<br>ä»¥å¾€éƒ½æ˜¯å‡è¨­å¥½æ©Ÿç‡æ¨¡å‹ä¸­çš„åƒæ•¸ï¼Œä¸¦è¨ˆç®—å…¶MLEï¼Œ<br>ç¾åœ¨é€éæ¨£æœ¬åŠæ¨£æœ¬æ‰€éš±è—çš„éš±è®Šæ•¸ï¼Œä¾†æ¨å°é©åˆé€™äº›æ¨£æœ¬çš„æ¨¡å‹åƒæ•¸ã€‚</p><h2 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h2><ul><li>argument : $y$ (éºå¤±å€¼æˆ–æ˜¯éš±è®Šæ•¸)</li><li>complete-data likelihood : $L(\theta|x,y)=p(x,y|\theta)$ åŠ å…¥éš±è®Šæ•¸å¾Œå®Œæ•´çš„æ¦‚ä¼¼å‡½æ•¸</li><li>What about $max_\theta L(x,y)$?</li><li>need to recursively update y and $\hat\theta$?</li></ul><h2 id="Eæ­¥é©Ÿ-æ›´æ–°y"><a href="#Eæ­¥é©Ÿ-æ›´æ–°y" class="headerlink" title="Eæ­¥é©Ÿ(æ›´æ–°y)"></a>Eæ­¥é©Ÿ(æ›´æ–°y)</h2><p>æ ¹æ“šç¾åœ¨çµ¦å®šçš„æ¨¡å‹åƒæ•¸åŠæ¨£æœ¬è§€æ¸¬å€¼ï¼Œæˆ‘å€‘å»è¨ˆç®—å…¶logå®Œæ•´æ¦‚ä¼¼å‡½æ•¸çš„æœŸæœ›å€¼å¦‚ä¸‹:<br>$$Q(\theta|\theta^{(t)})\equiv E_y[log p(x,y|\theta)|x,\theta^{(t)}]$$</p><h2 id="Mæ­¥é©Ÿ-æ›´æ–°åƒæ•¸-theta"><a href="#Mæ­¥é©Ÿ-æ›´æ–°åƒæ•¸-theta" class="headerlink" title="Mæ­¥é©Ÿ(æ›´æ–°åƒæ•¸$\theta$)"></a>Mæ­¥é©Ÿ(æ›´æ–°åƒæ•¸$\theta$)</h2><p>æœ€å¤§åŒ–Eæ­¥é©Ÿç²å¾—çš„æœŸæœ›å€¼<br>$$\theta^{(t+1)} = arg max_\theta  Q(\theta|\theta^{t})$$</p><p><strong>é‡è¤‡ä¸Šè¿°éç¨‹ç›´åˆ°æ”¶æ–‚</strong></p><h2 id="EMæ¨å°"><a href="#EMæ¨å°" class="headerlink" title="EMæ¨å°"></a>EMæ¨å°</h2><ul><li>$X:observed \space data$</li><li>$Y:latent\space variable$</li></ul><p>$Log\space likelihood \space function$</p><p>$$ l(\theta) $$</p><p>$$= lnP(X|\theta) $$</p><p>$$= ln\sum_yP(X,y|\theta) $$</p><p>$$= ln(\sum_yP(X,y|\theta))\frac{Q(y)}{Q(y)}$$</p><p>$$\ge\sum_yQ(y)ln\frac{P(X,y|\theta)}{Q(y)} $$</p><p>$$\because log \in concave\space by\space Jensenâ€™s\space inequality $$</p><p>$$(è§£æ±ºln\sum ä¸å¥½è¨ˆç®—çš„å•é¡Œï¼ŒQ:æ©Ÿç‡åˆ†é…) $$</p><p>$$= E_Q(ln\frac{P(X,y|\theta)}{Q(y)})$$</p><p>åœ¨$Jensenâ€™s \: inequality ä¸­ï¼Œç•¶E(x)ä¸­ï¼Œx=å¸¸æ•¸æ™‚ï¼Œç­‰è™Ÿæˆç«‹ã€‚$</p><p>$$\Rightarrow\frac{P(X,y|\theta)}{Q(y)}=c \in Constantï¼Œä¸”\sum_yQ(y)=1$$</p><p>$$\Rightarrow\sum_yP(X,y|\theta)=c\sum_yQ(y)=c$$</p><p>$$\Rightarrow Q(y)=\frac{P(X,y|\theta)}{\sum_yP(X,y|\theta)}=P(y|x_i,\theta)$$ï¼Œ</p><p>$$Q:åœ¨æ¨£æœ¬çµ¦å®šä¸‹ä¹‹éš±è—è®Šæ•¸æ¢ä»¶åˆ†å¸ƒ$$</p><p>$$\therefore E_Q(ln\frac{P(X,y|\theta)}{Q(y)})=E_y(ln\frac{P(X,y|\theta)}{P(y|x_i,\theta)}|X,\theta)$$</p><p>$$\theta^{(t+1)}=arg\max\limits_\theta l(\theta)\Longleftrightarrow arg\max\limits_\theta\sum_{y}P(y|x_i,\theta^{(t)})ln\frac{P(X,y|\theta)}{P(y|x_i,\theta^{(t)})}$$</p><p>$$\: \: \Longleftrightarrow arg\max\limits_\theta\sum_{y}P(y|x_i,\theta^{(t)})lnP(X,y|\theta)=E_y(lnP(X,y|\theta)|X,\theta^{(t)})=Q(\theta|\theta^{(t)})$$</p><p>$$\therefore E-step :Find \: Q(\theta|\theta^{(t)})$$</p><p>$\Longleftrightarrow$ Find the expectation of the complete-data loglikelihood with respect to the missing data y given the observed data x and the current parameter estimates $\theta^{(t)}$.</p><p>$$M-step=\theta^{(t+1)}=arg\max\limits_\theta Q(\theta|\theta^{(t)})$$</p><h2 id="EMæ”¶æ–‚æ€§"><a href="#EMæ”¶æ–‚æ€§" class="headerlink" title="EMæ”¶æ–‚æ€§"></a>EMæ”¶æ–‚æ€§</h2><hr><h2 id="ç¯„ä¾‹1"><a href="#ç¯„ä¾‹1" class="headerlink" title="ç¯„ä¾‹1"></a>ç¯„ä¾‹1</h2><p>197 animals are distributed multinomially into four categories with cell-probabilities$(\frac{1}{2}+ \frac{\theta}{4}, \frac{(1-\theta)}{4}, \frac{(1-\theta)}{4}, \frac{\theta}{4})$, where $\theta \in (0,1)$is unknown</p><p>Observed Data:<br>$$x=(x_1,x_2,x_3,x_4)=(125,18,20,34)$$</p><p>Likelihood:<br>$$L(\thetaï¼›x)=\frac{n!}{x_1!x_2!x_3!x_4!}(\frac{1}{2}+\frac{\theta}{4})^{x_1}(\frac{1}{4}-\frac{\theta}{4})^{x_2}(\frac{1}{4}-\frac{\theta}{4})^{x_3}(\frac{\theta}{4})^{x_4}$$</p><p>Find MLE by maximizing loglikelihood</p><p>Now use EM to find MLE</p><p>å‡è¨­æˆ‘å€‘çš„éš±è—è®Šæ•¸åœ¨aè£¡é¢ï¼Œä»¤$y=x_{11}+x_{12}$</p><p>å®Œæ•´çš„è®Šæ•¸æ“´å±•ç‚º$(x_{11},x_{12},x_{2},x_{3},x_{4})$æœ‰5å€‹</p><p>åˆå§‹å…¶åƒæ•¸  $(\frac{1}{2}, \frac{\theta}{4}, \frac{1}{4}-\frac{\theta}{4}, \frac{\theta}{4})$</p><p>å…¶æ¦‚ä¼¼å‡½æ•¸å¦‚ä¸‹</p><p>$$L(\thetaï¼›x)=\frac{n!}{x_{11}!x_{12}!x_2!x_3!x_4!}(\frac{1}{2})^{x_{11}}(\frac{\theta}{4})^{x_{12}}(\frac{1}{4}-\frac{\theta}{4})^{x_{2}+x_{3}}(\frac{\theta}{4})^{x_{4}}$$</p><ul><li>E æ­¥é©Ÿ</li></ul><p>çµ¦å®šæ©Ÿç‡æ¨¡å‹åƒæ•¸$\theta^{(t)}$å’Œ$(x_1,x_2,x_3,x_4)$ï¼Œ$$x_{11}=\frac{2x_{1}}{2+\theta}\quad and \quad x_{12}=\frac{\theta x_{1}}{2+\theta}$$</p><p>æ¨å°Qå‡½æ•¸(ä»¤$y=x_{12}$)<br>$$Q(\theta |\theta^{(t)})=E_y[log p(x,y|\theta)|x, \theta^{(t)}]$$</p><p>$$=E_y[(x_{12}+x_{4})log\theta +(x_{2}+x_{3})log(1-\theta)|x,\theta^{(t)}]$$</p><p>$$=(E_y[x_{12}|x, \theta^{(t)}]+x_{4})log\theta +(x_{2}+x_{3})log(1-\theta)$$</p><p>$$=(\frac{\theta^{(t)}x_{1}}{2+\theta^{(t)}}+x_{4})log\theta + (x_{2}+x_{3})log(1-\theta)$$</p><p>å…¶ä¸­$$x_{12}|_{x,\theta^{(t)}}\sim Binomial(x_{1},\frac{\theta^{(t)}}{2+\theta^{(t)}})$$</p><p>$$x_{12}^{(t)}=E_y[x_{12}|x,\theta^{(t)}]=\frac{\theta^{(t)}x_{1}}{2+\theta^{(t)}}$$</p><ul><li>M æ­¥é©Ÿ</li></ul><p>å°Qå‡½æ•¸é€²è¡Œå¾®åˆ†</p><p>çµ¦å®š$(x_{11},x_{12},x_{3},x_{4},x_{5})$</p><p>$$\theta^{(t+1)}=\frac{x_{12}^{(t)}+x_{4}}{x_{12}^{(t)}+x_{2}+x_{3}+x_{4}}$$</p><p><strong>é‡è¤‡ä»¥ä¸Šæ­¥é©Ÿåˆ°åƒæ•¸è¿­ä»£è‡³ç©©å®š</strong></p><h2 id="R-å¯¦ä½œ"><a href="#R-å¯¦ä½œ" class="headerlink" title="R å¯¦ä½œ"></a>R å¯¦ä½œ</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mult = <span class="keyword">function</span>(theta, x, n)&#123;</span><br><span class="line">    tmp = theta</span><br><span class="line">    <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:n)&#123;</span><br><span class="line">        <span class="comment"># E-step</span></span><br><span class="line">        x12 = x[<span class="number">1</span>]*(theta/ (<span class="number">2</span> + theta))</span><br><span class="line">        <span class="comment"># M-step</span></span><br><span class="line">        theta = (x12 + x[<span class="number">4</span>])/(x12 + x[<span class="number">2</span>] + x[<span class="number">3</span>] + x[<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">        tmp = c(tmp, theta)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">x=c(<span class="number">125</span>, <span class="number">18</span>, <span class="number">20</span>, <span class="number">34</span>)</span><br><span class="line">mult(<span class="number">0.1</span>, x, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><h2 id="ç¯„ä¾‹2"><a href="#ç¯„ä¾‹2" class="headerlink" title="ç¯„ä¾‹2"></a>ç¯„ä¾‹2</h2><h2 id="ç¯„ä¾‹3"><a href="#ç¯„ä¾‹3" class="headerlink" title="ç¯„ä¾‹3"></a>ç¯„ä¾‹3</h2><p>å‡è¨­ç¾åœ¨æœ‰å…©æšç¡¬å¹£Aã€B</p><ul><li><p><step1>æˆ‘å€‘ç”¨ä¸€æšå…¬æ­£çš„ç¡¬å¹£ä¾†æ±ºå®šï¼ŒæŠ•æ“² A æˆ– B ç¡¬å¹£</step1></p></li><li><p><step2>ä¾æ“š<step1>çµæœï¼ŒæŠ•æ“² A æˆ– B ç¡¬å¹£ 1æ¬¡ï¼Œè¨˜éŒ„å…¶çµæœ</step1></step2></p></li><li><p><step3>åè¦†é€²è¡Œnæ¬¡ï¼Œæœ€çµ‚å¯å¾—åˆ°é¡ä¼¼å¦‚ä¸‹çµæœ: 10111011â€¦.</step3></p><ul><li>1è¡¨ç¤ºæ­£é¢ï¼Œ0è¡¨ç¤ºåé¢</li></ul></li></ul><p>å¦‚æœæˆ‘å€‘ä»Šå¤©åªèƒ½è§€å¯Ÿåˆ°æœ€çµ‚çµæœ<step3>ï¼Œç„¡æ³•çŸ¥é“æ¯ä¸€æ¬¡æŠ•æ“²ä¾†è‡ªå“ªä¸€æšç¡¬å¹£ï¼Œè©²å¦‚ä½•ä¼°è¨ˆå‡ºå…©å€‹ç¡¬å¹£å‡ºç¾æ­£é¢æ©Ÿç‡?</step3></p><p><sol>:</sol></p><p>Observed Data : $X=(x_1,x_2,â€¦,x_n), x_i:æ­£é¢å‡ºç¾æ¬¡æ•¸$<br>Aã€B å‡ºç¾æ­£é¢æ©Ÿç‡ : $\theta =(p,q)$</p><p>$1^{\circ}$  å¾MLEæƒ³æ³•å‡ºç™¼</p><p>æ¦‚ä¼¼å‡½æ•¸ :<br>$$L(\theta|X)=P(X|\theta)=\prod_{i=1}^nP(x_i|\theta)$$</p><p>$$\hat p=\frac{ä½¿ç”¨Aç¡¬å¹£éª°åˆ°æ­£é¢æ¬¡æ•¸}{ä½¿ç”¨Aç¡¬å¹£ç¸½æŠ•æ“²æ¬¡æ•¸}$$</p><p>$$\hat q=\frac{ä½¿ç”¨Bç¡¬å¹£éª°åˆ°æ­£é¢æ¬¡æ•¸}{ä½¿ç”¨Bç¡¬å¹£ç¸½æŠ•æ“²æ¬¡æ•¸}$$</p><p>ä½†å› ç‚ºæˆ‘å€‘ä¸¦ä¸çŸ¥é“ $x_i$ä¾†è‡ªå“ªå€‹ç¡¬å¹£(æ©Ÿç‡æ¨¡å‹)ï¼Œæ‰€ä»¥ç„¡æ³•é€²è¡Œè¨ˆç®—ã€‚</p><p>$2^{\circ}$ å˜—è©¦æ·»åŠ éš±è—è®Šæ•¸ï¼Œä½¿å…¶è®Šæˆcomplete dataï¼Œé‹ç”¨EMæ¼”ç®—æ³•</p><ul><li><p>æ ¹æ“šobserved dataï¼Œæˆ‘å€‘ç„¡å¾å¾—çŸ¥ $x_i$ä¾†è‡ªå“ªå€‹ç¡¬å¹£(æ©Ÿç‡æ¨¡å‹)ï¼Œ    </p></li><li><p>å› æ­¤æˆ‘å€‘æ·»åŠ ä¸€å€‹éš±è—è®Šæ•¸ $y_i$ï¼Œå…¶è¡¨ç¤º $x_i$ ä¾†è‡ªå“ªå€‹ç¡¬å¹£ï¼Œ$Y=(y_1,y_2,â€¦,y_n)$</p></li></ul><p>$y_i = 1$ or $2$ï¼Œ$x_i|y_{i}=1 \sim Ber(p_{1})$ï¼Œ$x_i|y_{i}=2 \sim Ber(p_{2})$</p><p>E-step :</p><p>$$\Rightarrow Q(\theta|\theta^{(t)})=E_y[ln(p(x,y|\theta))|x,\theta ^{(t)}]=E_y[\sum_{i=1}^{n}ln(p(y_i|\theta)p(x_i|y_i,\theta))|x,\theta^{(t)}]$$</p><p>$$=\sum_{i=1}^{n}E_y[ln(p(y_i|\theta)p(x_i|y_i,\theta))|x,\theta^{(t)}]=\sum_{i=1}^{n}\sum_{y_i=0}^{1}[ln(p(y_i|\theta)p(x_i|y_i,\theta))p(y_i|x_i,\theta^{(t)} )]$$</p><p>$$=\sum_{i=1}^{n}\sum_{j=0}^{1}[ln(p(y_i=j|\theta)p(x_i|y_i,\theta))p(y_i=j|x_i,\theta^{(t)} )]$$</p><p>å…¶ä¸­$p(y_i=j|x_i,\theta^{(t)} )$ : åœ¨ç¬¬tæ¬¡è¿­ä»£ä¸‹ï¼Œç•¶å‰æ•¸æ“šä¾†è‡ªå“ªå€‹ç¡¬å¹£çš„æ©Ÿç‡</p><p>Q-step : </p><1><p>$$\frac{\partial Q}{\partial p}=\frac{\partial (\sum_{i=1}^{n}ln(\frac{1}{2}p^{x_i}(1-p)^{1-x_i})p(y_i=1|x_i,\theta^{(t)} )}{\partial p}$$</p><p>$$=\frac{\partial (\sum_{i=1}^{n}ln(\frac{1}{2})+x_iln(p)+(1-x_i)ln(1-p)p(y_i=1|x_i,\theta^{(t)} )}{\partial p}$$</p><p>$$=\sum_{i=1}^{n}(\frac{xi}{p}-\frac{(1-x_i)}{1-  p})p(y_i=1|x_i,\theta^{(t)} )=0$$</p><p>$$\Rightarrow p^{(t+1)}=\frac{\sum_{i=1}^{n}x_ip(y_i=1|x_i,\theta^{(t)})}{\sum_{i=1}^{n}p(y_i=1|x_i,\theta^{(t)})}$$</p><2><p>$$\frac{\partial Q}{\partial q}=0$$</p><p>åŒç†å¯å¾—,$$q^{(t+1)}=\frac{\sum_{i=1}^{n}x_ip(y_i=2|x_i,\theta^{(t)})}{\sum_{i=1}^{n}p(y_i=2|x_i,\theta^{(t)})}$$</p><p>$3^{\circ}$ ç¶œè§€ä»¥ä¸Šçµæœï¼Œå¯ä»¥ç™¼ç¾å¯¦éš›ä¸Šæˆ‘å€‘åªéœ€è¦è¨ˆç®—å‡º$p(y_i=j|x_i,\theta^{(t)} )$ï¼Œå°±å¯ä»¥æ‹¿ä¾†é€²è¡ŒEMè¿­ä»£ã€‚</p><p>$\Rightarrow$ çµ¦å®šåˆå§‹å€¼$(p^{(0)},q^{(0)})$ï¼Œè¨ˆç®—å‡º$p(y_i=j|x_i,\theta^{(0)} )$ï¼Œä»£å…¥æ›´æ–°åƒæ•¸$p^{(t+1)},q^{(t+1)}$ï¼Œé‡è¤‡è¿­ä»£ï¼Œç›´åˆ°æ”¶æ–‚æˆ–è€…é”åˆ°è‡ªè¡Œçµ¦å®štoleranceå…§.</p><p>$4^{\circ}$ è‹¥<step2>æ”¹æˆä¾æ“š<step1>çµæœï¼Œé€£çºŒæŠ•æ“² A æˆ– B ç¡¬å¹£ 10æ¬¡ï¼Œè¨˜éŒ„å…¶çµæœ</step1></step2></p><ul><li><step3>åè¦†é€²è¡Œnæ¬¡ï¼Œæœ€çµ‚å¯å¾—åˆ°é¡ä¼¼å¦‚ä¸‹çµæœ:<ul><li>1è¡¨ç¤ºæ­£é¢ï¼Œ0è¡¨ç¤ºåé¢</li></ul></step3></li></ul><p><img src="https://i.imgur.com/TIuGBly.png" alt=""></p><p>æœ€çµ‚Q-step çš„åƒæ•¸å…¬å¼ :<br>$$p^{(t+1)}=\frac{\sum_{i=1}^{n}x_ip(y_i=1|x_i,\theta^{(t)})}{\sum_{i=1}^{n}10p(y_i=1|x_i,\theta^{(t)}}$$</p><p>$$q^{(t+1)}=\frac{\sum_{i=1}^{n}x_ip(y_i=2|x_i,\theta^{(t)})}{\sum_{i=1}^{n}10p(y_i=2|x_i,\theta^{(t)})}$$</p><h2 id="Python-å¯¦ä½œ"><a href="#Python-å¯¦ä½œ" class="headerlink" title="Python å¯¦ä½œ"></a>Python å¯¦ä½œ</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5çµ„ç¡¬å¹£æŠ•æ“²çµæœ(n=5,k=10)ï¼Œ1ä»£è¡¨æ­£é¢ï¼Œ0ä»£è¡¨åé¢</span></span><br><span class="line">observations = np.array([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                         [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                         [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                         [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line">da=pd.DataFrame(observations,</span><br><span class="line">                index=[<span class="string">"ç¬¬ä¸€æ¬¡"</span>,<span class="string">"ç¬¬äºŒæ¬¡"</span>,<span class="string">"ç¬¬ä¸‰æ¬¡"</span>,<span class="string">"ç¬¬å››æ¬¡"</span>,<span class="string">"ç¬¬äº”æ¬¡"</span>])</span><br><span class="line">da.columns = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>];da</span><br><span class="line"></span><br><span class="line"><span class="comment">###</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">em_single</span><span class="params">(priors,observations)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    EMç®—æ³•-å–®æ¬¡ç–Šä»£</span></span><br><span class="line"><span class="string">    ------------</span></span><br><span class="line"><span class="string">    priors:[theta_A,theta_B]</span></span><br><span class="line"><span class="string">    observation:[m X n matrix]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    ---------------</span></span><br><span class="line"><span class="string">    new_priors:[new_theta_A,new_theta_B]</span></span><br><span class="line"><span class="string">    :param priors:</span></span><br><span class="line"><span class="string">    :param observations:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    counts = &#123;<span class="string">'A'</span>: &#123;<span class="string">'H'</span>: <span class="number">0</span>, <span class="string">'T'</span>: <span class="number">0</span>&#125;, <span class="string">'B'</span>: &#123;<span class="string">'H'</span>: <span class="number">0</span>, <span class="string">'T'</span>: <span class="number">0</span>&#125;&#125;</span><br><span class="line">    theta_A = priors[<span class="number">0</span>]</span><br><span class="line">    theta_B = priors[<span class="number">1</span>]</span><br><span class="line">    <span class="comment">#E step</span></span><br><span class="line">    <span class="keyword">for</span> observation <span class="keyword">in</span> observations:</span><br><span class="line">        len_observation = len(observation)      <span class="comment">#è¨ˆç®—æŠ•æ“²æ¬¡æ•¸</span></span><br><span class="line">        num_heads = observation.sum()           <span class="comment">#æ­£é¢æ¬¡æ•¸</span></span><br><span class="line">        num_tails = len_observation-num_heads   <span class="comment">#åé¢æ¬¡æ•¸</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#äºŒé …åˆ†é…å…¬å¼æ±‚è§£</span></span><br><span class="line">        contribution_A = scipy.stats.binom.pmf(num_heads,len_observation,theta_A)    <span class="comment">#Bin(x,n,p)</span></span><br><span class="line">        contribution_B = scipy.stats.binom.pmf(num_heads,len_observation,theta_B)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#è¨ˆç®—åœ¨çµ¦å®šè³‡æ–™ã€ç•¶å‰åƒæ•¸ä¸‹ï¼Œè³‡æ–™ä¾†è‡ªå“ªå€‹ç¡¬å¹£çš„æ©Ÿç‡</span></span><br><span class="line">        weight_A = contribution_A / (contribution_A + contribution_B)     <span class="comment"># p(y=1|x,theta)</span></span><br><span class="line">        weight_B = contribution_B / (contribution_A + contribution_B)     <span class="comment"># p(y=0|x,theta)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#æ›´æ–°åœ¨ç•¶å‰åƒæ•¸ä¸‹Aï¼ŒBç¡¬å¹£ç”¢ç”Ÿçš„æ­£åé¢æ¬¡æ•¸</span></span><br><span class="line">        counts[<span class="string">'A'</span>][<span class="string">'H'</span>] += weight_A * num_heads  <span class="comment"># num += 1  =&gt; num = num+1ï¼Œ sum p(y_i=1|x,theta)*x_i</span></span><br><span class="line">        counts[<span class="string">'A'</span>][<span class="string">'T'</span>] += weight_A * num_tails</span><br><span class="line">        counts[<span class="string">'B'</span>][<span class="string">'H'</span>] += weight_B * num_heads</span><br><span class="line">        counts[<span class="string">'B'</span>][<span class="string">'T'</span>] += weight_B * num_tails</span><br><span class="line"></span><br><span class="line">    <span class="comment"># M step</span></span><br><span class="line">    new_theta_A = counts[<span class="string">'A'</span>][<span class="string">'H'</span>] / (counts[<span class="string">'A'</span>][<span class="string">'H'</span>] + counts[<span class="string">'A'</span>][<span class="string">'T'</span>])  <span class="comment">#sum p(y_i=1|x,theta)*x_i / sum 10*p(y_i=1|x,theta)</span></span><br><span class="line">    new_theta_B = counts[<span class="string">'B'</span>][<span class="string">'H'</span>] / (counts[<span class="string">'B'</span>][<span class="string">'H'</span>] + counts[<span class="string">'B'</span>][<span class="string">'T'</span>])  <span class="comment">#sum p(y_i=0|x,theta)*x_i / sum 10*p(y_i=1|x,theta)</span></span><br><span class="line">    <span class="keyword">return</span> [new_theta_A,new_theta_B]</span><br><span class="line">    </span><br><span class="line"><span class="comment">###</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">em</span><span class="params">(observations,prior,tol = <span class="number">1e-6</span>,iterations=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    EMç®—æ³•</span></span><br><span class="line"><span class="string">    ï¼šparam observations :è§€æ¸¬æ•¸æ“š</span></span><br><span class="line"><span class="string">    ï¼šparam priorï¼šæ¨¡å‹åˆå§‹å€¼</span></span><br><span class="line"><span class="string">    ï¼šparam tolï¼šè¿­ä»£ç»“æŸé˜ˆå€¼</span></span><br><span class="line"><span class="string">    ï¼šparam iterationsï¼šæœ€å¤§è¿­ä»£æ¬¡æ•¸</span></span><br><span class="line"><span class="string">    ï¼šreturnï¼šå±€éƒ¨æœ€ä½³çš„æ¨¡å‹åƒæ•¸</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    iteration = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> iteration &lt; iterations:</span><br><span class="line">        new_prior = em_single(prior,observations)</span><br><span class="line">        delta_change = np.abs(prior[<span class="number">0</span>]-new_prior[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> delta_change &lt; tol:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            prior = new_prior</span><br><span class="line">            iteration +=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> new_prior,iteration</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"(p,q,iteration)="</span>,em(observations,[<span class="number">0.7</span>,<span class="number">0.5</span>]))</span><br></pre></td></tr></table></figure><p>Ans : (p,q,iteration)= ([0.79678865844706648, 0.51958340803243785], 12)</p></2></1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/1121509ac1dc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;åƒè€ƒç¶²å€&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://web.mit.edu/6.435/www/Dempste
      
    
    </summary>
    
      <category term="æ©Ÿå™¨å­¸ç¿’" scheme="https://caocharles.github.io/categories/machine-learning/"/>
    
    
      <category term="EM" scheme="https://caocharles.github.io/tags/EM/"/>
    
      <category term="Algorithm" scheme="https://caocharles.github.io/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>æˆ‘çš„æ¸¬è©¦æ–‡ç« </title>
    <link href="https://caocharles.github.io/%E6%88%91%E7%9A%84%E6%B8%AC%E8%A9%A6%E6%96%87%E7%AB%A0/"/>
    <id>https://caocharles.github.io/æˆ‘çš„æ¸¬è©¦æ–‡ç« /</id>
    <published>2018-08-27T08:23:30.000Z</published>
    <updated>2018-09-04T13:47:53.821Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://caocharles.github.io/">é€£çµæ¸¬è©¦</a></p><p>æ‰“æ‰“çœ‹æ–‡å­—ã€‚</p><p>12345</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x+2y =5</span><br></pre></td></tr></table></figure><p>$$\sigma$$ </p><p>$$\frac{1}{2}$$ </p><p><a href="https://www.bigdatauniversity.com" target="_blank" rel="noopener"><img src="https://ibm.box.com/shared/static/jvcqp2iy2jlx2b32rmzdt0tx8lvxgzkp.png" width="300," align="center"></a></p><h1 align="center"><font size="5"> TENSORFLOWâ€™S HELLO WORLD</font></h1><div class="alert alert-block alert-info" style="margin-top: 20px"><br><font size="3"><strong>In this notebook we will overview the basics of TensorFlow, learn itâ€™s structures and see what is the motivation to use it</strong></font><br><br><br> - <p><a href="#ref2">How does TensorFlow work?</a></p><br> - <p><a href="#ref3">Building a Graph</a></p><br> - <p><a href="#ref4">Defining multidimensional arrays using TensorFlow</a></p><br> - <p><a href="#ref5">Why Tensors?</a></p><br> - <p><a href="#ref6">Variables</a></p><br> - <p><a href="#ref7">Placeholders</a></p><br> - <p><a href="#ref8">Operations</a></p><br><p></p><br></div><br><br><br><br>â€”â€”â€”â€”â€”-<br><br><a id="ref2"></a><br><br># How does TensorFlow work?<br><br>TensorFlowâ€™s capability to execute the code on different devices such as CPUs and GPUs is a consequence of itâ€™s specific structure:<br><br>TensorFlow defines computations as Graphs, and these are made with operations (also know as â€œopsâ€). So, when we work with TensorFlow, it is the same as defining a series of operations in a Graph.<br><br>To execute these operations as computations, we must launch the Graph into a Session. The session translates and passes the operations represented into the graphs to the device you want to execute them on, be it a GPU or CPU.<br><br>For example, the image below represents a graph in TensorFlow. _W_, _x_ and b are tensors over the edges of this graph. _MatMul_ is an operation over the tensors _W_ and _x_, after that _Add_ is called and add the result of the previous operator with _b_. The resultant tensors of each operation cross the next one until the end where itâ€™s possible to get the wanted result.<br><br><img src="https://ibm.box.com/shared/static/a94cgezzwbkrq02jzfjjljrcaozu5s2q.png"><br><br><br>### Importing TensorFlow<br><p>To use TensorFlow, we need to import the library. We imported it and optionally gave it the name â€œtfâ€, so the modules can be accessed by <strong>tf.module-name</strong>:<br><br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure><br><br>â€”â€”â€”â€”â€”â€“<br><br><a id="ref3"></a><br># Building a Graph<br><br>As we said before, TensorFlow works as a graph computational model. Letâ€™s create our first graph.<br><br>To create our first graph we will utilize <strong>source operations</strong>, which do not need any information input. These source operations or <strong>source ops</strong> will pass their information to other operations which will execute computations.<br><br>To create two source operations which will output numbers we will define two constants:<br><br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">2</span>])</span><br><span class="line">b = tf.constant([<span class="number">3</span>])</span><br></pre></td></tr></table></figure><br><br>After that, letâ€™s make an operation over these variables. The function <strong>tf.add()</strong> adds two elements (you could also use <code>c = a + b</code>).<br><br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c = tf.add(a,b)</span><br><span class="line"><span class="comment">#c = a + b is also a way to define the sum of the terms</span></span><br></pre></td></tr></table></figure><br><br>Then TensorFlow needs to initialize a session to run our code. Sessions are, in a way, a context for creating a graph inside TensorFlow. Letâ€™s define our session:<br><br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">session = tf.Session()</span><br></pre></td></tr></table></figure><br><br>Letâ€™s run the session to get the result from the previous defined â€˜câ€™ operation:<br><br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = session.run(c)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><br><br>Close the session to release resources:<br><br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">session.close()</span><br></pre></td></tr></table></figure><br><br>To avoid having to close sessions every time, we can define them in a <strong>with</strong> block, so after running the <strong>with</strong> block the session will close automatically:<br><br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">    result = session.run(c)</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure><br><br>Even this silly example of adding 2 constants to reach a simple result defines the basis of TensorFlow. Define your edge (In this case our constants), include nodes (operations, like _tf.add_), and start a session to build a graph.<br><br><br><br>### What is the meaning of Tensor?<br><br><div class="alert alert-success alertsuccess" style="margin-top: 20px"><br><font size="3"><strong>In TensorFlow all data is passed between operations in a computation graph, and these are passed in the form of Tensors, hence the name of TensorFlow.</strong></font><br><br><br><br><br>The word <strong>tensor</strong> from new latin means â€œthat which stretchesâ€. It is a mathematical object that is named <strong>tensor</strong>  because an early application of tensors was the study of materials stretching under tension. The contemporary meaning of tensors can be taken as multidimensional arrays.<br><br><p></p><br><br></div></p><p>Thatâ€™s great, butâ€¦ what are these multidimensional arrays? </p><p>Going back a little bit to physics to understand the concept of dimensions:<br><br><img src="https://ibm.box.com/shared/static/ymn0hl3hf8s3xb4k15v22y5vmuodnue1.svg"></p><div style="text-align:center"><a href="https://en.wikipedia.org/wiki/Dimension" target="_blank" rel="noopener">[Image Source]</a> </div><p>The zero dimension can be seen as a point, a single object or a single item.</p><p>The first dimension can be seen as a line, a one-dimensional array can be seen as numbers along this line, or as points along the line. One dimension can contain infinite zero dimension/points elements.</p><p>The second dimension can be seen as a surface, a two-dimensional array can be seen as an infinite series of lines along an infinite line. </p><p>The third dimension can be seen as volume, a three-dimensional array can be seen as an infinite series of surfaces along an infinite line.</p><p>The Fourth dimension can be seen as the hyperspace or spacetime, a volume varying through time, or an infinite series of volumes along an infinite line. And so forth onâ€¦</p><p>As mathematical objects: <br><br><br><img src="https://ibm.box.com/shared/static/kmxz570uai8eeg6i6ynqdz6kmlx1m422.png"></p><div style="text-align:center"><a href="https://book.mql4.com/variables/arrays" target="_blank" rel="noopener">[Image Source]</a></div><p>Summarizing:<br><br></p><table style="width:100%"><br>  <tr><br>    <td><b>Dimension</b></td><br>    <td><b>Physical Representation</b></td><br>    <td><b>Mathematical Object</b></td><br>    <td><b>In Code</b></td><br>  </tr><br><br>  <tr><br>    <td>Zero </td><br>    <td>Point</td><br>    <td>Scalar (Single Number)</td><br>    <td>[ 1 ]</td><br>  </tr><br><br>  <tr><br>    <td>One</td><br>    <td>Line</td><br>    <td>Vector (Series of Numbers) </td><br>    <td>[ 1,2,3,4,â€¦ ]</td><br>  </tr><br><br>   <tr><br>    <td>Two</td><br>    <td>Surface</td><br>    <td>Matrix (Table of Numbers)</td><br>    <td>[ [1,2,3,4,â€¦], [1,2,3,4,â€¦], [1,2,3,4,â€¦],â€¦ ]</td><br>  </tr><br><br>   <tr><br>    <td>Three</td><br>    <td>Volume</td><br>    <td>Tensor (Cube of Numbers)</td><br>    <td>[ [[1,2,â€¦], [1,2,â€¦], [1,2,â€¦],â€¦], [[1,2,â€¦], [1,2,â€¦], [1,2,â€¦],â€¦], [[1,2,â€¦], [1,2,â€¦], [1,2,â€¦] ,â€¦]â€¦ ]</td><br>  </tr><br><br></table><hr><p><a id="ref4"></a></p><h1 id="Defining-multidimensional-arrays-using-TensorFlow"><a href="#Defining-multidimensional-arrays-using-TensorFlow" class="headerlink" title="Defining multidimensional arrays using TensorFlow"></a>Defining multidimensional arrays using TensorFlow</h1><p>Now we will try to define such arrays using TensorFlow:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Scalar = tf.constant([<span class="number">2</span>])</span><br><span class="line">Vector = tf.constant([<span class="number">5</span>,<span class="number">6</span>,<span class="number">2</span>])</span><br><span class="line">Matrix = tf.constant([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]])</span><br><span class="line">Tensor = tf.constant( [ [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]] , [[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]] , [[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],[<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],[<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>]] ] )</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">    result = session.run(Scalar)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Scalar (1 entry):\n %s \n"</span> % result)</span><br><span class="line">    result = session.run(Vector)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Vector (3 entries) :\n %s \n"</span> % result)</span><br><span class="line">    result = session.run(Matrix)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Matrix (3x3 entries):\n %s \n"</span> % result)</span><br><span class="line">    result = session.run(Tensor)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Tensor (3x3x3 entries) :\n %s \n"</span> % result)</span><br></pre></td></tr></table></figure><p>Now that you understand these data structures, I encourage you to play with them using some previous functions to see how they will behave, according to their structure types:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Matrix_one = tf.constant([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]])</span><br><span class="line">Matrix_two = tf.constant([[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line">first_operation = tf.add(Matrix_one, Matrix_two)</span><br><span class="line">second_operation = Matrix_one + Matrix_two</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">    result = session.run(first_operation)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Defined using tensorflow function :"</span>)</span><br><span class="line">    print(result)</span><br><span class="line">    result = session.run(second_operation)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Defined using normal expressions :"</span>)</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure><p>With the regular symbol definition and also the TensorFlow function we were able to get an element-wise multiplication, also known as Hadamard product. <br></p><p>But what if we want the regular matrix product?</p><p>We then need to use another TensorFlow function called <strong>tf.matmul()</strong>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Matrix_one = tf.constant([[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">Matrix_two = tf.constant([[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"></span><br><span class="line">first_operation = tf.matmul(Matrix_one, Matrix_two)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">    result = session.run(first_operation)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Defined using tensorflow function :"</span>)</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure><p>We could also define this multiplication ourselves, but there is a function that already does that, so no need to reinvent the wheel!</p><hr><p><a id="ref5"></a></p><h1 id="Why-Tensors"><a href="#Why-Tensors" class="headerlink" title="Why Tensors?"></a>Why Tensors?</h1><p>The Tensor structure helps us by giving the freedom to shape the dataset the way we want.</p><p>And it is particularly helpful when dealing with images, due to the nature of how information in images are encoded,</p><p>Thinking about images, its easy to understand that it has a height and width, so it would make sense to represent the information contained in it with a two dimensional strucutre (a matrix)â€¦ until you remember that images have colors, and to add information about the colors, we need another dimension, and thats when Tensors become particulary helpful.</p><p>Images are encoded into color channels, the image data is represented into each color intensity in a color channel at a given point, the most common one being RGB, which means Red, Blue and Green. The information contained into an image is the intensity of each channel color into the width and height of the image, just like this:</p><p><img src="https://ibm.box.com/shared/static/xlpv9h5xws248c09k1rlx7cer69y4grh.png"></p><div style="text-align:center"><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/dn424131.aspx" target="_blank" rel="noopener">[Image Source]</a></div><p>So the intensity of the red channel at each point with width and height can be represented into a matrix, the same goes for the blue and green channels, so we end up having three matrices, and when these are combined they form a tensor. </p><hr><p><a id="ref6"></a></p><h1 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h1><p>Now that we are more familiar with the structure of data, we will take a look at how TensorFlow handles variables.</p><p>To define variables we use the command <strong>tf.variable()</strong>.<br>To be able to use variables in a computation graph it is necessary to initialize them before running the graph in a session. This is done by running <strong>tf.global_variables_initializer()</strong>.</p><p>To update the value of a variable, we simply run an assign operation that assigns a value to the variable:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">state = tf.Variable(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>Letâ€™s first create a simple counter, a variable that increases one unit at a time:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">one = tf.constant(<span class="number">1</span>)</span><br><span class="line">new_value = tf.add(state, one)</span><br><span class="line">update = tf.assign(state, new_value)</span><br></pre></td></tr></table></figure><p>Variables must be initialized by running an initialization operation after having launched the graph.  We first have to add the initialization operation to the graph:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init_op = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><p>We then start a session to run the graph, first initialize the variables, then print the initial value of the <strong>state</strong> variable, and then run the operation of updating the <strong>state</strong> variable and printing the result after each update:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">  session.run(init_op)</span><br><span class="line">  print(session.run(state))</span><br><span class="line">  <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    session.run(update)</span><br><span class="line">    print(session.run(state))</span><br></pre></td></tr></table></figure><hr><p><a id="ref7"></a></p><h1 id="Placeholders"><a href="#Placeholders" class="headerlink" title="Placeholders"></a>Placeholders</h1><p>Now we know how to manipulate variables inside TensorFlow, but what about feeding data outside of a TensorFlow model? </p><p>If you want to feed data to a TensorFlow model from outside a model, you will need to use placeholders.</p><p>So what are these placeholders and what do they do? </p><p>Placeholders can be seen as â€œholesâ€ in your model, â€œholesâ€ which you will pass the data to, you can create them using <br> <b>tf.placeholder(_datatype_)</b>, where <b>_datatype_</b> specifies the type of data (integers, floating points, strings, booleans) along with its precision (8, 16, 32, 64) bits.</p><p>The definition of each data type with the respective python sintax is defined as:</p><table><thead><tr><th>Data type</th><th>Python type</th><th>Description</th></tr></thead><tbody><tr><td>DT_FLOAT</td><td>tf.float32</td><td>32 bits floating point.</td></tr><tr><td>DT_DOUBLE</td><td>tf.float64</td><td>64 bits floating point.</td></tr><tr><td>DT_INT8</td><td>tf.int8</td><td>8 bits signed integer.</td></tr><tr><td>DT_INT16</td><td>tf.int16</td><td>16 bits signed integer.</td></tr><tr><td>DT_INT32</td><td>tf.int32</td><td>32 bits signed integer.</td></tr><tr><td>DT_INT64</td><td>tf.int64</td><td>64 bits signed integer.</td></tr><tr><td>DT_UINT8</td><td>tf.uint8</td><td>8 bits unsigned integer.</td></tr><tr><td>DT_STRING</td><td>tf.string</td><td>Variable length byte arrays. Each element of a Tensor is a byte array.</td></tr><tr><td>DT_BOOL</td><td>tf.bool</td><td>Boolean.</td></tr><tr><td>DT_COMPLEX64</td><td>tf.complex64</td><td>Complex number made of two 32 bits floating points: real and imaginary parts.</td></tr><tr><td>DT_COMPLEX128</td><td>tf.complex128</td><td>Complex number made of two 64 bits floating points: real and imaginary parts.</td></tr><tr><td>DT_QINT8</td><td>tf.qint8</td><td>8 bits signed integer used in quantized Ops.</td></tr><tr><td>DT_QINT32</td><td>tf.qint32</td><td>32 bits signed integer used in quantized Ops.</td></tr><tr><td>DT_QUINT8</td><td>tf.quint8</td><td>8 bits unsigned integer used in quantized Ops.</td></tr></tbody></table><div style="text-align:center"><a href="https://www.tensorflow.org/versions/r0.9/resources/dims_types.html" target="_blank" rel="noopener">[Table Source]</a></div><p>So we create a placeholder:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tf.placeholder(tf.float32)</span><br></pre></td></tr></table></figure><p>And define a simple multiplication operation:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b = a*<span class="number">2</span></span><br></pre></td></tr></table></figure><p>Now we need to define and run the session, but since we created a â€œholeâ€ in the model to pass the data, when we initialize the session we are obligated to pass an argument with the data, otherwise we would get an error.</p><p>To pass the data to the model we call the session with an extra argument <b> feed_dict</b> in which we should pass a dictionary with each placeholder name folowed by its respective data, just like this:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    result = sess.run(b,feed_dict=&#123;a:<span class="number">3.5</span>&#125;)</span><br><span class="line">    <span class="keyword">print</span> (result)</span><br></pre></td></tr></table></figure><p>Since data in TensorFlow is passed in form of multidimensional arrays we can pass any kind of tensor through the placeholders to get the answer to the simple multiplication operation:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dictionary=&#123;a: [ [ [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],[<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>] ] , [ [<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>],[<span class="number">16</span>,<span class="number">17</span>,<span class="number">18</span>],[<span class="number">19</span>,<span class="number">20</span>,<span class="number">21</span>],[<span class="number">22</span>,<span class="number">23</span>,<span class="number">24</span>] ] ] &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    result = sess.run(b,feed_dict=dictionary)</span><br><span class="line">    <span class="keyword">print</span> (result)</span><br></pre></td></tr></table></figure><hr><p><a id="ref8"></a></p><h1 id="Operations"><a href="#Operations" class="headerlink" title="Operations"></a>Operations</h1><p>Operations are nodes that represent the mathematical operations over the tensors on a graph. These operations can be any kind of functions, like add and subtract tensor or maybe an activation function.</p><p>_tf.matmul_, _tf.add_, _tf.nn.sigmoid_ are some of the operations in TensorFlow. These are like functions in python but operate directly over tensors and each one does a specific thing. </p><div class="alert alert-success alertsuccess" style="margin-top: 20px">Other operations can be easily found in: <a href="https://www.tensorflow.org/versions/r0.9/api_docs/python/index.html" target="_blank" rel="noopener">https://www.tensorflow.org/versions/r0.9/api_docs/python/index.html</a></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">5</span>])</span><br><span class="line">b = tf.constant([<span class="number">2</span>])</span><br><span class="line">c = tf.add(a,b)</span><br><span class="line">d = tf.subtract(a,b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">    result = session.run(c)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'c =: %s'</span> % result)</span><br><span class="line">    result = session.run(d)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'d =: %s'</span> % result)</span><br></pre></td></tr></table></figure><p>_tf.nn.sigmoid_ is an activiation function, itâ€™s a little more complicated, but this function helps learning models to evaluate what kind of information is good or not.</p><hr><h2 id="Want-to-learn-more"><a href="#Want-to-learn-more" class="headerlink" title="Want to learn more?"></a>Want to learn more?</h2><p>Running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBMâ€™s Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The PowerAI platform supports popular machine learning libraries and dependencies including Tensorflow, Caffe, Torch, and Theano. You can download a <a href="https://cocl.us/ML0120EN_PAI" target="_blank" rel="noopener">free version of PowerAI</a>.</p><p>Also, you can use Data Science Experience to run these notebooks faster with bigger datasets. Data Science Experience is IBMâ€™s leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, DSX enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of DSX users today with a free account at <a href="https://cocl.us/ML0120EN_DSX" target="_blank" rel="noopener">Data Science Experience</a>This is the end of this lesson. Hopefully, now you have a deeper and intuitive understanding regarding the LSTM model. Thank you for reading this notebook, and good luck on your studies.</p><h3 id="Thanks-for-completing-this-lesson"><a href="#Thanks-for-completing-this-lesson" class="headerlink" title="Thanks for completing this lesson!"></a>Thanks for completing this lesson!</h3><p>Notebook created by: <a href="https://ca.linkedin.com/in/rafaelblsilva" target="_blank" rel="noopener"> Rafael Belo Da Silva </a> </p><h3 id="References"><a href="#References" class="headerlink" title="References:"></a>References:</h3><p><a href="https://www.tensorflow.org/versions/r0.9/get_started/index.html" target="_blank" rel="noopener">https://www.tensorflow.org/versions/r0.9/get_started/index.html</a><br><br><a href="http://jrmeyer.github.io/tutorial/2016/02/01/TensorFlow-Tutorial.html" target="_blank" rel="noopener">http://jrmeyer.github.io/tutorial/2016/02/01/TensorFlow-Tutorial.html</a><br><br><a href="https://www.tensorflow.org/versions/r0.9/api_docs/python/index.html" target="_blank" rel="noopener">https://www.tensorflow.org/versions/r0.9/api_docs/python/index.html</a><br><br><a href="https://www.tensorflow.org/versions/r0.9/resources/dims_types.html" target="_blank" rel="noopener">https://www.tensorflow.org/versions/r0.9/resources/dims_types.html</a><br><br><a href="https://en.wikipedia.org/wiki/Dimension" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Dimension</a><br><br><a href="https://book.mql4.com/variables/arrays" target="_blank" rel="noopener">https://book.mql4.com/variables/arrays</a><br><br><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/dn424131(v=vs.85).aspx" target="_blank" rel="noopener">https://msdn.microsoft.com/en-us/library/windows/desktop/dn424131(v=vs.85).aspx</a><br></p><p><hr><br>Copyright &copy; 2016 <a href="https://bigdatauniversity.com/?utm_source=bducopyrightlink&amp;utm_medium=dswb&amp;utm_campaign=bdu" target="_blank" rel="noopener">Big Data University</a>. This notebook and its source code are released under the terms of the <a href="https://bigdatauniversity.com/mit-license/" target="_blank" rel="noopener">MIT License</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://caocharles.github.io/&quot;&gt;é€£çµæ¸¬è©¦&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ‰“æ‰“çœ‹æ–‡å­—ã€‚&lt;/p&gt;
&lt;p&gt;12345&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gut
      
    
    </summary>
    
      <category term="é€™æ˜¯åˆ†é¡" scheme="https://caocharles.github.io/categories/%E9%80%99%E6%98%AF%E5%88%86%E9%A1%9E/"/>
    
      <category term="é€™æ˜¯å­åˆ†é¡" scheme="https://caocharles.github.io/categories/%E9%80%99%E6%98%AF%E5%88%86%E9%A1%9E/%E9%80%99%E6%98%AF%E5%AD%90%E5%88%86%E9%A1%9E/"/>
    
    
      <category term="é€™æ˜¯æ¨™ç±¤" scheme="https://caocharles.github.io/tags/%E9%80%99%E6%98%AF%E6%A8%99%E7%B1%A4/"/>
    
      <category term="é€™æ˜¯æ¨™ç±¤2" scheme="https://caocharles.github.io/tags/%E9%80%99%E6%98%AF%E6%A8%99%E7%B1%A42/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://caocharles.github.io/hello-world/"/>
    <id>https://caocharles.github.io/hello-world/</id>
    <published>2018-08-27T07:58:15.056Z</published>
    <updated>2018-08-27T07:58:15.057Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
